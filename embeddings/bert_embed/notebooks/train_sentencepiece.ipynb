{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-08T07:24:38.867189Z","iopub.status.busy":"2024-04-08T07:24:38.866711Z","iopub.status.idle":"2024-04-08T07:24:54.556695Z","shell.execute_reply":"2024-04-08T07:24:54.555182Z","shell.execute_reply.started":"2024-04-08T07:24:38.867155Z"},"trusted":true},"outputs":[],"source":["!pip install transformers[torch] datasets torch numpy sentencepiece"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["INP_HF_DATASET_PATH = '/kaggle/input/iwslt-en-zh/ds'\n","INP_SPM_MODEL_PATH = '/kaggle/input/spiecebpeunproc/other/base-spiece/1/en.model'\n","INP_SRC_LANG = 'en'\n","\n","OUTPUT_PATH = \"/kaggle/working/models\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T07:24:54.561200Z","iopub.status.busy":"2024-04-08T07:24:54.559168Z","iopub.status.idle":"2024-04-08T07:24:54.571308Z","shell.execute_reply":"2024-04-08T07:24:54.570103Z","shell.execute_reply.started":"2024-04-08T07:24:54.561160Z"},"trusted":true},"outputs":[],"source":["import datasets\n","import numpy as np\n","import torch\n","from torch.utils.data import RandomSampler\n","from transformers import (\n","    BertConfig,\n","    BertForMaskedLM,\n","    BertTokenizerFast,\n","    DataCollatorForLanguageModeling,\n","    Trainer,\n","    TrainingArguments,\n","    BatchEncoding\n",")\n","import sentencepiece as spm"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T07:24:54.574463Z","iopub.status.busy":"2024-04-08T07:24:54.573428Z","iopub.status.idle":"2024-04-08T07:24:54.583308Z","shell.execute_reply":"2024-04-08T07:24:54.582056Z","shell.execute_reply.started":"2024-04-08T07:24:54.574426Z"},"trusted":true},"outputs":[],"source":["dev = \"CPU\"\n","device = torch.device(\"cpu\")\n","if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n","    dev = \"MPS\"\n","    device = torch.device(\"mps\")\n","elif torch.cuda.is_available() and torch.cuda.device_count():\n","    dev = \"CUDA\"\n","    device = torch.device(\"cuda\")\n","torch.set_default_device(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T07:24:54.590066Z","iopub.status.busy":"2024-04-08T07:24:54.587805Z","iopub.status.idle":"2024-04-08T07:24:54.797253Z","shell.execute_reply":"2024-04-08T07:24:54.796059Z","shell.execute_reply.started":"2024-04-08T07:24:54.590024Z"},"trusted":true},"outputs":[],"source":["ds = datasets.load_from_disk(INP_HF_DATASET_PATH)\n","\n","t = ds['train']\n","\n","v = ds['validation']"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T07:36:41.790964Z","iopub.status.busy":"2024-04-08T07:36:41.790500Z","iopub.status.idle":"2024-04-08T07:36:41.824651Z","shell.execute_reply":"2024-04-08T07:36:41.823232Z","shell.execute_reply.started":"2024-04-08T07:36:41.790928Z"},"trusted":true},"outputs":[],"source":["from collections.abc import Mapping\n","\n","SEQUENCE_LENGTH = 288\n","\n","\n","class Tokeniser:\n","    out_keys = [\n","        \"input_ids\",\n","        \"token_type_ids\",\n","        \"attention_mask\",\n","        \"special_tokens_mask\",\n","    ]\n","\n","    def __init__(self, lang, model_file):\n","        self.lang = lang\n","        self.model = spm.SentencePieceProcessor(model_file=model_file)\n","\n","        self.pad_token_id = 3\n","        self.bos_id = self.model.bos_id()\n","        self.eos_id = self.model.eos_id()\n","\n","    def _process_id(self, input_ids):\n","        input_ids = [self.bos_id, *input_ids, self.eos_id]\n","        o_len = len(input_ids)\n","        token_type_ids = [0] * o_len\n","        attention_mask = [1] * o_len\n","        special_tokens_mask = [1] + [0] * (o_len - 2) + [1]\n","\n","        if o_len > SEQUENCE_LENGTH:\n","            input_ids = input_ids[: SEQUENCE_LENGTH - 1] + [self.eos_id]\n","            token_type_ids = token_type_ids[:SEQUENCE_LENGTH]\n","            attention_mask = attention_mask[:SEQUENCE_LENGTH]\n","            special_tokens_mask = special_tokens_mask[: SEQUENCE_LENGTH - 1] + [1]\n","\n","        elif o_len < SEQUENCE_LENGTH:\n","            # EOS\n","            input_ids += [self.eos_id]\n","\n","            # Padding\n","            input_ids += [self.pad_token_id] * (SEQUENCE_LENGTH - len(input_ids))\n","\n","            token_type_ids += [0] * (SEQUENCE_LENGTH - len(token_type_ids))\n","            attention_mask += [0] * (SEQUENCE_LENGTH - len(attention_mask))\n","\n","            # Padding\n","            special_tokens_mask += [1] * (SEQUENCE_LENGTH - len(special_tokens_mask))\n","\n","        return {\n","            \"input_ids\": input_ids,\n","            \"token_type_ids\": token_type_ids,\n","            \"attention_mask\": attention_mask,\n","            \"special_tokens_mask\": special_tokens_mask,\n","        }\n","\n","    def encode(self, row):\n","        if isinstance(row, list):\n","            return self.encode_batch(row)\n","\n","        raw_ids = self.model.encode(row)\n","        return self._process_id(raw_ids)\n","\n","    def encode_batch(self, rows):\n","        ids = list(map(lambda row: self._process_id(row), self.model.encode(rows)))\n","        return {key: [example[key] for example in ids] for key in Tokeniser.out_keys}\n","\n","    def pad(self, inputs, **_kwargs):\n","        if (\n","            isinstance(inputs, (list, tuple))\n","            and len(inputs) > 0\n","            and isinstance(inputs[0], Mapping)\n","        ):\n","            inputs = {\n","                key: [example[key] for example in inputs] for key in Tokeniser.out_keys\n","            }\n","        return BatchEncoding(inputs, tensor_type=\"pt\")\n","\n","    def __call__(self, inputs, **_kwargs):\n","        return self.encode(inputs)\n","\n","    def __len__(self):\n","        return len(self.model)\n","\n","\n","tokenizer = Tokeniser(INP_SRC_LANG, model_file=INP_SPM_MODEL_PATH)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T07:34:42.625848Z","iopub.status.busy":"2024-04-08T07:34:42.625236Z","iopub.status.idle":"2024-04-08T07:36:05.167304Z","shell.execute_reply":"2024-04-08T07:36:05.165597Z","shell.execute_reply.started":"2024-04-08T07:34:42.625804Z"},"trusted":true},"outputs":[],"source":["# Given batch, maps input -> { 'input_ids': list[list], 'token_type_ids', 'attention_mask', 'special_tokens_mask'}\n","def get_row_data(batch):\n","    out = tokenizer(\n","        list(map(lambda r: r[INP_SRC_LANG], batch[\"translation\"])),\n","    )    \n","    return out\n","\n","\n","train_dataset = t.map(get_row_data, batched=True)\n","test_dataset = v.map(get_row_data, batched=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T07:36:05.170005Z","iopub.status.busy":"2024-04-08T07:36:05.169538Z","iopub.status.idle":"2024-04-08T07:36:05.180665Z","shell.execute_reply":"2024-04-08T07:36:05.179375Z","shell.execute_reply.started":"2024-04-08T07:36:05.169963Z"},"trusted":true},"outputs":[],"source":["config = BertConfig(\n","    vocab_size=len(tokenizer),\n","    max_position_embeddings=288,  # or 512 (sentence length for attn mask)\n","    hidden_size=256,\n","    num_attention_heads=8\n","    # Add or modify other config parameters as needed\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T07:36:44.722995Z","iopub.status.busy":"2024-04-08T07:36:44.722512Z","iopub.status.idle":"2024-04-08T07:36:45.634738Z","shell.execute_reply":"2024-04-08T07:36:45.633744Z","shell.execute_reply.started":"2024-04-08T07:36:44.722955Z"},"trusted":true},"outputs":[],"source":["\n","\n","model = BertForMaskedLM(config)\n","\n","# Important: Tokenizer impls __len__ for output vocab size\n","model.resize_token_embeddings(len(tokenizer))\n","\n","data_collator = DataCollatorForLanguageModeling(\n","    tokenizer=tokenizer,\n","    mlm=False,  # Disable Masked Language Modeling\n",")\n","\n","training_args = TrainingArguments(\n","    output_dir=OUTPUT_PATH,\n","    evaluation_strategy=\"steps\",\n","    overwrite_output_dir=True,\n","    num_train_epochs=20,\n","    per_device_train_batch_size=10,\n","    gradient_accumulation_steps=8,\n","    per_device_eval_batch_size=64,\n","    logging_steps=1000,\n","    save_steps=1000,\n","    load_best_model_at_end=True,\n","    save_total_limit=3,\n","    use_cpu=dev == \"CPU\",\n","    dataloader_pin_memory=False,\n","    fp16=dev != \"CPU\"\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=train_dataset,\n","    eval_dataset=test_dataset,\n",")\n","\n","trainer._get_train_sampler = lambda: RandomSampler(\n","    trainer.train_dataset, generator=torch.Generator(device)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T07:26:21.258780Z","iopub.status.busy":"2024-04-08T07:26:21.258387Z","iopub.status.idle":"2024-04-08T07:26:21.474236Z","shell.execute_reply":"2024-04-08T07:26:21.472222Z","shell.execute_reply.started":"2024-04-08T07:26:21.258745Z"},"trusted":true},"outputs":[],"source":["from kaggle_secrets import UserSecretsClient\n","import wandb\n","user_secrets = UserSecretsClient()\n","secret_value_0 = user_secrets.get_secret(\"wandb_sec\")\n","wandb.login(key=secret_value_0)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T07:36:46.986248Z","iopub.status.busy":"2024-04-08T07:36:46.985591Z","iopub.status.idle":"2024-04-08T07:38:58.916101Z","shell.execute_reply":"2024-04-08T07:38:58.913263Z","shell.execute_reply.started":"2024-04-08T07:36:46.986212Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","np.object = object\n","trainer.train()\n","trainer.save_model(OUTPUT_PATH)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4634136,"sourceId":7892746,"sourceType":"datasetVersion"},{"isSourceIdPinned":true,"modelInstanceId":22150,"sourceId":26323,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30673,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":4}
