{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForMaskedLM, BertTokenizerFast\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokeniser\n",
    "\n",
    "We are required to:\n",
    "\n",
    "* Add special tokens to the start and end of each sentence.\n",
    "* Pad & truncate all sentences to a single constant length.\n",
    "* Explicitly differentiate real tokens from padding tokens with the “attention mask”.\n",
    "\n",
    "#### Special Tokens `[SEP]`\n",
    "\n",
    "At the end of every sentence, we need to append the special `[SEP]` token.\n",
    "\n",
    "This token is an artifact of two-sentence tasks, where BERT is given two separate sentences and asked to determine something (e.g., can the answer to the question in sentence A be found in sentence B?).\n",
    "\n",
    "I am not certain yet why the token is still required when we have only single-sentence input, but it is!\n",
    "\n",
    "#### `[CLS]`\n",
    "\n",
    "For classification tasks, we must prepend the special [CLS] token to the beginning of every sentence.\n",
    "\n",
    "This token has special significance. BERT consists of 12 Transformer layers. Each transformer takes in a list of token embeddings, and produces the same number of embeddings on the output (but with the feature values changed, of course!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_LANG = 'en'\n",
    "TOK_DIR = '../../tokenisation'\n",
    "\n",
    "DATA_DIR = f'{TOK_DIR}/data'\n",
    "DATA_PATH = f'{DATA_DIR}/iwslt2017-en-zh.{SRC_LANG}'\n",
    "\n",
    "SPM_DIR = f'{TOK_DIR}/sentencepiece_custom'\n",
    "SPM_PATH = f'{SPM_DIR}/{SRC_LANG}.model'\n",
    "\n",
    "MODEL_DIR = '../../models'\n",
    "BERT_MODEL_PATH = f'{MODEL_DIR}/bert-embed/BPE-bert-{SRC_LANG}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_tokeniser import BPEBertTokeniser\n",
    "\n",
    "tokeniser = BPEBertTokeniser(SRC_LANG, model_file=SPM_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokeniser = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(16384, 256, padding_idx=0)\n",
       "      (position_embeddings): Embedding(288, 256)\n",
       "      (token_type_embeddings): Embedding(2, 256)\n",
       "      (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=256, out_features=16384, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForMaskedLM.from_pretrained(BERT_MODEL_PATH, output_hidden_states=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture Explained\n",
    "\n",
    "#### Input \n",
    "\n",
    "As shown, it takes index mappings for the words and outputs an input layer of size 768. In this case, the tokeniser has a vocab size of 30522.\n",
    "\n",
    "(pls help)\n",
    "It also takes positional encodings of 300, meaning it can process sentences of length 300? \n",
    " \n",
    "It also takes token type embeddings of size 2 - giving 2 possible types of tokens (0 or 1). 0 means padding. In this case, our sentences are padded to a constant length of 300.\n",
    "\n",
    "#### Output\n",
    "\n",
    "It will output the token indices, which when fed to the tokeniser will return the tokens. Given that BERTTokenizer uses some form of WordPiece, the tokens with type 1 shld be joined with the previous ones, while tokens with type 0 are start tokens? May need to investigate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(16384, 256, padding_idx=0)\n",
       "      (position_embeddings): Embedding(288, 256)\n",
       "      (token_type_embeddings): Embedding(2, 256)\n",
       "      (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=256, out_features=16384, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "dataset = datasets.load_dataset(\"iwslt2017\", \"iwslt2017-en-zh\")\n",
    "\n",
    "train, test = dataset['train'], dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Thank you so much, Chris. And it's truly a great honor to have the opportunity to come to this stage twice; I'm extremely grateful.\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = train[0]['translation']['en']\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [v['en'] for v in train['translation'][:10]]\n",
    "\n",
    "from transformers import BatchEncoding\n",
    "\n",
    "batch = tokeniser(t, padding='max_length', max_length=64, return_special_tokens_mask=True)\n",
    "v = BatchEncoding(batch, tensor_type='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 288])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [1, 652, 48, 124, 397, 16257, 2766, 16259, 76, 61, 16262, 16244, 2764, 6, 560, 4806, 25, 107, 9, 1887, 25, 536, 25, 80, 2192, 3489, 16300, 36, 16262, 16251, 2569, 6318, 16259, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'special_tokens_mask': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "print(tokeniser(sent, padding='max_length', max_length=64, return_special_tokens_mask=True))\n",
    "\n",
    "\n",
    "# Input Ids: Token IDs\n",
    "# Token Type IDs: to research, for now all 0\n",
    "# Attn Mask: all 1s, padding 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BPEBertTokeniser' object has no attribute 'pad_token'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtokeniser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BPEBertTokeniser' object has no attribute 'pad_token'"
     ]
    }
   ],
   "source": [
    "tokeniser.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokeniser(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BPEBertTokeniser' object has no attribute 'tokenize'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokens \u001b[38;5;241m=\u001b[39m \u001b[43mtokeniser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m(sent)\n\u001b[1;32m      2\u001b[0m indices \u001b[38;5;241m=\u001b[39m tokeniser\u001b[38;5;241m.\u001b[39mconvert_tokens_to_ids(tokens)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m indice, token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(indices, tokens):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BPEBertTokeniser' object has no attribute 'tokenize'"
     ]
    }
   ],
   "source": [
    "tokens = tokeniser.tokenize(sent)\n",
    "indices = tokeniser.convert_tokens_to_ids(tokens)\n",
    "for indice, token in zip(indices, tokens):\n",
    "    print(indice, token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indice_tensor = torch.tensor([indices])\n",
    "segment_tensor = torch.zeros(indice_tensor.shape) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokeniser(sent, return_special_tokens_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 288])\n",
      "Number of layers: 13   (initial embeddings + 12 BERT layers)\n",
      "Number of batches: 1\n",
      "Number of tokens: 288\n",
      "Number of hidden units: 256\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    tokens = tokeniser(sent)\n",
    "    input_ids = torch.tensor(tokens['input_ids']).reshape((1, -1))\n",
    "    token_type_ids = torch.tensor([tokens['token_type_ids']])\n",
    "    attention_mask = torch.tensor([tokens['attention_mask']])\n",
    "\n",
    "    print(input_ids.shape)\n",
    "\n",
    "    output = model(input_ids, token_type_ids, attention_mask)\n",
    "    hidden_states = output.hidden_states\n",
    "\n",
    "    print (\"Number of layers:\", len(hidden_states), \"  (initial embeddings + 12 BERT layers)\")\n",
    "    layer_i = 0\n",
    "\n",
    "    print (\"Number of batches:\", len(hidden_states[layer_i]))\n",
    "    batch_i = 0\n",
    "\n",
    "    print (\"Number of tokens:\", len(hidden_states[layer_i][batch_i]))\n",
    "    token_i = 0\n",
    "\n",
    "    print (\"Number of hidden units:\", len(hidden_states[layer_i][batch_i][token_i]))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 1, 288, 256])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 288, 256])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([288, 13, 256])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings = token_embeddings.permute(1,0,2)\n",
    "\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Append Last 4 Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stores the token vectors, with shape [22 x 3,072]\n",
    "token_vecs_cat = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "    \n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Concatenate the vectors (that is, append them together) from the last \n",
    "    # four layers.\n",
    "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "    cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "    \n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs_cat.append(cat_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_cat), len(token_vecs_cat[0])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum Last 4 Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 288 x 256\n"
     ]
    }
   ],
   "source": [
    "# Stores the token vectors, with shape [22 x 768]\n",
    "token_vecs_sum = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "\n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Sum the vectors from the last four layers.\n",
    "    sum_vec = torch.sum(token[-4:], dim=0)\n",
    "    \n",
    "    # Use `sum_vec` to represent `token`.\n",
    "    token_vecs_sum.append(sum_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_sum), len(token_vecs_sum[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `hidden_states` has shape [13 x 1 x 22 x 768]\n",
    "\n",
    "# `token_vecs` is a tensor with shape [22 x 768]\n",
    "token_vecs = hidden_states[-2][0]\n",
    "\n",
    "# Calculate the average of all 22 token vectors.\n",
    "sentence_embedding = torch.mean(token_vecs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Our final sentence embedding vector of shape:\", sentence_embedding.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenised_text = tokeniser.tokenize(sent)\n",
    "\n",
    "for id, tok in enumerate(tokenised_text):\n",
    "    print(id, tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 vector values for each instance of \"to\".\n",
      "\n",
      "honor to have    tensor([ 0.3083, -1.3135, -0.8791,  2.0045,  0.7318])\n",
      "opportunity to come   tensor([ 0.7557, -4.7355,  0.4427, -6.3347, -4.0329])\n",
      "come to this    tensor([ 1.9014, -5.0590,  3.2812, -0.9040,  2.8231])\n"
     ]
    }
   ],
   "source": [
    "print('First 5 vector values for each instance of \"to\".')\n",
    "print('')\n",
    "print(\"honor to have   \", str(token_vecs_sum[15][:5]))\n",
    "print(\"opportunity to come  \", str(token_vecs_sum[19][:5]))\n",
    "print(\"come to this   \", str(token_vecs_sum[21][:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector similarity for  *similar*  meanings:  0.39\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Cosine Similarity\n",
    "\n",
    "May wish to test with other examples of ambiguous words ('river bank', 'bank robber')\n",
    "\"\"\"\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Calculate the cosine similarity between the word bank\n",
    "# for to\n",
    "same_to = 1 - cosine(token_vecs_sum[19], token_vecs_sum[21])\n",
    "\n",
    "print('Vector similarity for  *similar*  meanings:  %.2f' % same_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class Embedding(nn.Module):\n",
    "    def __init__(self, tokeniser=None):\n",
    "        super().__init__()\n",
    "        if not tokeniser:\n",
    "            self.tokeniser = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "        else:\n",
    "            self.tokeniser = tokeniser\n",
    "        self.model = BertForMaskedLM.from_pretrained(\n",
    "            '../../models/bert-embed/bert', \n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        self.model.eval()\n",
    "    def forward(self, sentence: str):\n",
    "        input_ids = torch.tensor([tokens['input_ids']])\n",
    "        token_type_ids = torch.tensor([tokens['token_type_ids']])\n",
    "        attention_mask = torch.tensor([tokens['attention_mask']])\n",
    "        with torch.no_grad():\n",
    "            output = model(input_ids, attention_mask, token_type_ids)\n",
    "            hidden_states = output.hidden_states\n",
    "            token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "            token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "            token_embeddings = token_embeddings.permute(1,0,2)\n",
    "\n",
    "            \"\"\"\n",
    "            TOKEN SUM VEC\n",
    "            \"\"\"\n",
    "            token_vecs_sum = []\n",
    "            # `token_embeddings` is a [len x 12 x 768] tensor.\n",
    "            # For each token in the sentence...\n",
    "            for token in token_embeddings:\n",
    "                # `token` is a [12 x 768] tensor\n",
    "                # Sum the vectors from the last four layers.\n",
    "                sum_vec = torch.sum(token[-4:], dim=0)\n",
    "                # Use `sum_vec` to represent `token`.\n",
    "                token_vecs_sum.append(sum_vec)\n",
    "            token_embedding_output = torch.vstack(token_vecs_sum)\n",
    "            \n",
    "            return {\n",
    "                'Token': token_embedding_output,\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_bert = Embedding()\n",
    "\n",
    "output = custom_bert.forward(train[0]['translation']['en'])\n",
    "\n",
    "output['Token'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapper over BaseBPETokeniser to output masks similar to BertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPEforBERTTokenizer(object):\n",
    "    def __init__(self, en_model_file=None, zh_model_file=None):\n",
    "        self.bpe_tokenizer = BaseBPETokeniser(en_model_file=en_model_file, zh_model_file=zh_model_file)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Both the english and chinese tokenisers have the same length.\n",
    "        \"\"\"\n",
    "        return len(self.bpe_tokenizer)\n",
    "\n",
    "    def __call__(self, sent: str, text_target=None, max_len=128, max_zh_len=None):\n",
    "        out, len_out = self.bpe_tokenizer(sent, text_target=text_target, max_len=max_len, max_zh_len=max_zh_len) #len_out includes SOS and EOS\n",
    "        out['token_type_ids'] = [0] * max_len\n",
    "        out['special_tokens_mask'] = [1] + [0] * (len_out - 2) + [1] * (max_len - len_out + 1)\n",
    "        out['attention_mask'] = [1] * len_out + [0] * (max_len - len_out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokeniser_bert = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "tokeniser_bert(dataset['train']['translation'][0]['en']).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentencepiece_custom.tokeniser import BaseBPETokeniser\n",
    "\n",
    "tokeniser = BaseBPETokeniser(zh_model_file=\"./sentencepiece_custom/zh.model\", en_model_file=\"./sentencepiece_custom/en.model\")\n",
    "(tokeniser(dataset['train']['translation'][0]['en'], max_len=288)[0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokeniser.get_special_ids('en'))\n",
    "print(tokeniser.get_special_ids('zh'))\n",
    "\n",
    "# returns (UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokeniser2 = BPEforBERTTokenizer(zh_model_file=\"./sentencepiece_custom/zh.model\", en_model_file=\"./sentencepiece_custom/en.model\")\n",
    "test = tokeniser2(dataset['train']['translation'][0]['en'], max_len=288)\n",
    "import numpy as np\n",
    "for key in test.keys():\n",
    "  curr = np.array(test[key])\n",
    "  print(key)\n",
    "  print(len(curr))\n",
    "  print(curr)\n",
    "\n",
    "  print(len(curr[curr == 3]))\n",
    "  print(len(curr[curr == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tokeniser2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset['train']['translation'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
