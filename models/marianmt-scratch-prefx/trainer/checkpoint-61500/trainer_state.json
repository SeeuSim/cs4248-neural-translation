{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.254583189207887,
  "eval_steps": 500,
  "global_step": 61500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03,
      "grad_norm": 1.220960259437561,
      "learning_rate": 0.00029827049463853337,
      "loss": 7.8036,
      "step": 500
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.0413414239883423,
      "learning_rate": 0.0002965444482877897,
      "loss": 7.5628,
      "step": 1000
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.3380242586135864,
      "learning_rate": 0.00029481840193704595,
      "loss": 7.5175,
      "step": 1500
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.9185484647750854,
      "learning_rate": 0.00029308889657557935,
      "loss": 7.4523,
      "step": 2000
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.4904528856277466,
      "learning_rate": 0.00029135939121411274,
      "loss": 7.419,
      "step": 2500
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.8736823201179504,
      "learning_rate": 0.00028962988585264614,
      "loss": 7.3408,
      "step": 3000
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.9295303821563721,
      "learning_rate": 0.00028790038049117953,
      "loss": 7.2978,
      "step": 3500
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.8265310525894165,
      "learning_rate": 0.00028617087512971287,
      "loss": 7.2895,
      "step": 4000
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.9134194850921631,
      "learning_rate": 0.00028444136976824626,
      "loss": 7.2899,
      "step": 4500
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6781627535820007,
      "learning_rate": 0.00028271186440677966,
      "loss": 7.2724,
      "step": 5000
    },
    {
      "epoch": 0.38,
      "grad_norm": 4.557011604309082,
      "learning_rate": 0.00028098235904531305,
      "loss": 7.2607,
      "step": 5500
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.8685030341148376,
      "learning_rate": 0.0002792528536838464,
      "loss": 7.2629,
      "step": 6000
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.7031558156013489,
      "learning_rate": 0.0002775233483223798,
      "loss": 7.2546,
      "step": 6500
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.581017017364502,
      "learning_rate": 0.0002757938429609132,
      "loss": 7.2689,
      "step": 7000
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.64484441280365,
      "learning_rate": 0.0002740677966101695,
      "loss": 7.2972,
      "step": 7500
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.6113131046295166,
      "learning_rate": 0.00027233829124870284,
      "loss": 7.2439,
      "step": 8000
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6621057391166687,
      "learning_rate": 0.00027060878588723624,
      "loss": 7.2578,
      "step": 8500
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.9122613072395325,
      "learning_rate": 0.00026887928052576963,
      "loss": 7.244,
      "step": 9000
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.5030791759490967,
      "learning_rate": 0.00026714977516430297,
      "loss": 7.2651,
      "step": 9500
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.5956907272338867,
      "learning_rate": 0.00026542026980283637,
      "loss": 7.3305,
      "step": 10000
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.5354079008102417,
      "learning_rate": 0.00026369076444136976,
      "loss": 7.3306,
      "step": 10500
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.8703756928443909,
      "learning_rate": 0.00026196125907990316,
      "loss": 7.3355,
      "step": 11000
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.7591487169265747,
      "learning_rate": 0.0002602352127291595,
      "loss": 7.3099,
      "step": 11500
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.9906620383262634,
      "learning_rate": 0.0002585057073676928,
      "loss": 7.3244,
      "step": 12000
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.6954877376556396,
      "learning_rate": 0.0002567762020062262,
      "loss": 7.3245,
      "step": 12500
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.7104721665382385,
      "learning_rate": 0.0002550466966447596,
      "loss": 7.3296,
      "step": 13000
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.9229937195777893,
      "learning_rate": 0.00025332065029401587,
      "loss": 7.3361,
      "step": 13500
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.5270612835884094,
      "learning_rate": 0.00025159114493254926,
      "loss": 7.3231,
      "step": 14000
    },
    {
      "epoch": 1.0,
      "eval_bleu": 0.0,
      "eval_gen_len": 511.0,
      "eval_loss": 10.908864974975586,
      "eval_runtime": 8102.4289,
      "eval_samples_per_second": 1.055,
      "eval_steps_per_second": 0.066,
      "step": 14455
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.078959345817566,
      "learning_rate": 0.00024986163957108266,
      "loss": 7.3206,
      "step": 14500
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.6107462644577026,
      "learning_rate": 0.00024813213420961605,
      "loss": 7.3111,
      "step": 15000
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.7726598978042603,
      "learning_rate": 0.00024640262884814945,
      "loss": 7.31,
      "step": 15500
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.8010438084602356,
      "learning_rate": 0.0002446765824974057,
      "loss": 7.2969,
      "step": 16000
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.435037612915039,
      "learning_rate": 0.0002429470771359391,
      "loss": 7.316,
      "step": 16500
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.5293745994567871,
      "learning_rate": 0.00024121757177447247,
      "loss": 7.3057,
      "step": 17000
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.6925299763679504,
      "learning_rate": 0.00023948806641300587,
      "loss": 7.2992,
      "step": 17500
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.7116979956626892,
      "learning_rate": 0.00023776202006226216,
      "loss": 7.2953,
      "step": 18000
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.8747738599777222,
      "learning_rate": 0.00023603251470079555,
      "loss": 7.3228,
      "step": 18500
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.6461837291717529,
      "learning_rate": 0.00023430300933932892,
      "loss": 7.3197,
      "step": 19000
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.0446981191635132,
      "learning_rate": 0.00023257350397786232,
      "loss": 7.2904,
      "step": 19500
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.4092074930667877,
      "learning_rate": 0.0002308439986163957,
      "loss": 7.3016,
      "step": 20000
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.5140671730041504,
      "learning_rate": 0.00022912141127637493,
      "loss": 7.3116,
      "step": 20500
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.207865834236145,
      "learning_rate": 0.00022739190591490832,
      "loss": 7.3031,
      "step": 21000
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.5510585308074951,
      "learning_rate": 0.00022566240055344172,
      "loss": 7.3103,
      "step": 21500
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.7820494771003723,
      "learning_rate": 0.00022393289519197506,
      "loss": 7.2951,
      "step": 22000
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.5837593674659729,
      "learning_rate": 0.00022220338983050845,
      "loss": 7.3101,
      "step": 22500
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.5265955924987793,
      "learning_rate": 0.00022047734347976477,
      "loss": 7.3464,
      "step": 23000
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.5297508239746094,
      "learning_rate": 0.0002187512971290211,
      "loss": 7.4111,
      "step": 23500
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.6367987990379333,
      "learning_rate": 0.00021702179176755446,
      "loss": 7.345,
      "step": 24000
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.6315511465072632,
      "learning_rate": 0.00021529228640608785,
      "loss": 7.3268,
      "step": 24500
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.6590219736099243,
      "learning_rate": 0.00021356278104462124,
      "loss": 7.3278,
      "step": 25000
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.5381798148155212,
      "learning_rate": 0.00021183327568315458,
      "loss": 7.319,
      "step": 25500
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.492324560880661,
      "learning_rate": 0.0002101072293324109,
      "loss": 7.3171,
      "step": 26000
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.6752819418907166,
      "learning_rate": 0.0002083777239709443,
      "loss": 7.3276,
      "step": 26500
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.6944257616996765,
      "learning_rate": 0.00020664821860947767,
      "loss": 7.3116,
      "step": 27000
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.7007157802581787,
      "learning_rate": 0.00020491871324801103,
      "loss": 7.3139,
      "step": 27500
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.5677017569541931,
      "learning_rate": 0.00020318920788654443,
      "loss": 7.3259,
      "step": 28000
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.6479864716529846,
      "learning_rate": 0.00020145970252507782,
      "loss": 7.3077,
      "step": 28500
    },
    {
      "epoch": 2.0,
      "eval_bleu": 0.0,
      "eval_gen_len": 511.0,
      "eval_loss": 9.334989547729492,
      "eval_runtime": 8406.1528,
      "eval_samples_per_second": 1.017,
      "eval_steps_per_second": 0.064,
      "step": 28910
    },
    {
      "epoch": 2.01,
      "grad_norm": 1.0581393241882324,
      "learning_rate": 0.00019973019716361122,
      "loss": 7.2987,
      "step": 29000
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.5007467865943909,
      "learning_rate": 0.00019800069180214456,
      "loss": 7.2994,
      "step": 29500
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.45748069882392883,
      "learning_rate": 0.00019627118644067795,
      "loss": 7.2951,
      "step": 30000
    },
    {
      "epoch": 2.11,
      "grad_norm": 0.71931391954422,
      "learning_rate": 0.00019454168107921135,
      "loss": 7.2973,
      "step": 30500
    },
    {
      "epoch": 2.14,
      "grad_norm": 0.7079980969429016,
      "learning_rate": 0.00019281217571774469,
      "loss": 7.2999,
      "step": 31000
    },
    {
      "epoch": 2.18,
      "grad_norm": 0.4425187408924103,
      "learning_rate": 0.00019108267035627808,
      "loss": 7.2837,
      "step": 31500
    },
    {
      "epoch": 2.21,
      "grad_norm": 1.1907367706298828,
      "learning_rate": 0.00018935316499481148,
      "loss": 7.297,
      "step": 32000
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.6412783265113831,
      "learning_rate": 0.00018762365963334484,
      "loss": 7.3086,
      "step": 32500
    },
    {
      "epoch": 2.28,
      "grad_norm": 0.6691833734512329,
      "learning_rate": 0.00018589415427187824,
      "loss": 7.2755,
      "step": 33000
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.7243739366531372,
      "learning_rate": 0.0001841646489104116,
      "loss": 7.2843,
      "step": 33500
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.6337279081344604,
      "learning_rate": 0.00018243860255966792,
      "loss": 7.2891,
      "step": 34000
    },
    {
      "epoch": 2.39,
      "grad_norm": 0.5368536710739136,
      "learning_rate": 0.00018070909719820132,
      "loss": 7.2952,
      "step": 34500
    },
    {
      "epoch": 2.42,
      "grad_norm": 0.6740288734436035,
      "learning_rate": 0.00017897959183673466,
      "loss": 7.2944,
      "step": 35000
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.7397432327270508,
      "learning_rate": 0.00017725008647526805,
      "loss": 7.2963,
      "step": 35500
    },
    {
      "epoch": 2.49,
      "grad_norm": 0.45871660113334656,
      "learning_rate": 0.00017552058111380145,
      "loss": 7.291,
      "step": 36000
    },
    {
      "epoch": 2.53,
      "grad_norm": 0.8727402687072754,
      "learning_rate": 0.00017379453476305777,
      "loss": 7.2757,
      "step": 36500
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.5565688014030457,
      "learning_rate": 0.0001720650294015911,
      "loss": 7.2951,
      "step": 37000
    },
    {
      "epoch": 2.59,
      "grad_norm": 0.5473604202270508,
      "learning_rate": 0.0001703355240401245,
      "loss": 7.2963,
      "step": 37500
    },
    {
      "epoch": 2.63,
      "grad_norm": 0.47138041257858276,
      "learning_rate": 0.00016861985472154962,
      "loss": 7.2962,
      "step": 38000
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.49803921580314636,
      "learning_rate": 0.000166890349360083,
      "loss": 7.298,
      "step": 38500
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.5403661727905273,
      "learning_rate": 0.00016516084399861638,
      "loss": 7.2934,
      "step": 39000
    },
    {
      "epoch": 2.73,
      "grad_norm": 0.903359055519104,
      "learning_rate": 0.00016343133863714978,
      "loss": 7.2851,
      "step": 39500
    },
    {
      "epoch": 2.77,
      "grad_norm": 0.5801020860671997,
      "learning_rate": 0.00016170183327568314,
      "loss": 7.3101,
      "step": 40000
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.7004584074020386,
      "learning_rate": 0.0001599723279142165,
      "loss": 7.2989,
      "step": 40500
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.5236108899116516,
      "learning_rate": 0.0001582428225527499,
      "loss": 7.2954,
      "step": 41000
    },
    {
      "epoch": 2.87,
      "grad_norm": 1.099437952041626,
      "learning_rate": 0.0001565133171912833,
      "loss": 7.2925,
      "step": 41500
    },
    {
      "epoch": 2.91,
      "grad_norm": 0.82578444480896,
      "learning_rate": 0.00015478381182981664,
      "loss": 7.289,
      "step": 42000
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.41454166173934937,
      "learning_rate": 0.00015305430646835003,
      "loss": 7.2792,
      "step": 42500
    },
    {
      "epoch": 2.97,
      "grad_norm": 0.5417740941047668,
      "learning_rate": 0.00015132480110688343,
      "loss": 7.2828,
      "step": 43000
    },
    {
      "epoch": 3.0,
      "eval_bleu": 0.0,
      "eval_gen_len": 511.0,
      "eval_loss": 11.560840606689453,
      "eval_runtime": 8396.7555,
      "eval_samples_per_second": 1.018,
      "eval_steps_per_second": 0.064,
      "step": 43365
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.5188248157501221,
      "learning_rate": 0.0001495952957454168,
      "loss": 7.2826,
      "step": 43500
    },
    {
      "epoch": 3.04,
      "grad_norm": 0.8204332590103149,
      "learning_rate": 0.00014786579038395016,
      "loss": 7.2834,
      "step": 44000
    },
    {
      "epoch": 3.08,
      "grad_norm": 0.6698409914970398,
      "learning_rate": 0.00014613628502248356,
      "loss": 7.2772,
      "step": 44500
    },
    {
      "epoch": 3.11,
      "grad_norm": 1.4293171167373657,
      "learning_rate": 0.00014440677966101695,
      "loss": 7.283,
      "step": 45000
    },
    {
      "epoch": 3.15,
      "grad_norm": 0.7043642401695251,
      "learning_rate": 0.00014267727429955032,
      "loss": 7.2735,
      "step": 45500
    },
    {
      "epoch": 3.18,
      "grad_norm": 0.4655408263206482,
      "learning_rate": 0.0001409477689380837,
      "loss": 7.288,
      "step": 46000
    },
    {
      "epoch": 3.22,
      "grad_norm": 0.4774252772331238,
      "learning_rate": 0.00013921826357661708,
      "loss": 7.2754,
      "step": 46500
    },
    {
      "epoch": 3.25,
      "grad_norm": 0.359225332736969,
      "learning_rate": 0.00013748875821515045,
      "loss": 7.2913,
      "step": 47000
    },
    {
      "epoch": 3.29,
      "grad_norm": 1.0019949674606323,
      "learning_rate": 0.00013575925285368384,
      "loss": 7.2766,
      "step": 47500
    },
    {
      "epoch": 3.32,
      "grad_norm": 0.816683828830719,
      "learning_rate": 0.00013403320650294014,
      "loss": 7.2798,
      "step": 48000
    },
    {
      "epoch": 3.36,
      "grad_norm": 0.6620227694511414,
      "learning_rate": 0.00013230370114147353,
      "loss": 7.285,
      "step": 48500
    },
    {
      "epoch": 3.39,
      "grad_norm": 0.7214509844779968,
      "learning_rate": 0.00013057419578000693,
      "loss": 7.2794,
      "step": 49000
    },
    {
      "epoch": 3.42,
      "grad_norm": 0.608234167098999,
      "learning_rate": 0.0001288446904185403,
      "loss": 7.2752,
      "step": 49500
    },
    {
      "epoch": 3.46,
      "grad_norm": 0.5833454728126526,
      "learning_rate": 0.00012711864406779658,
      "loss": 7.2817,
      "step": 50000
    },
    {
      "epoch": 3.49,
      "grad_norm": 0.336582750082016,
      "learning_rate": 0.00012538913870632998,
      "loss": 7.282,
      "step": 50500
    },
    {
      "epoch": 3.53,
      "grad_norm": 0.5830754637718201,
      "learning_rate": 0.00012365963334486335,
      "loss": 7.2865,
      "step": 51000
    },
    {
      "epoch": 3.56,
      "grad_norm": 0.4629668593406677,
      "learning_rate": 0.00012193012798339673,
      "loss": 7.2624,
      "step": 51500
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.5374818444252014,
      "learning_rate": 0.00012020062262193012,
      "loss": 7.2746,
      "step": 52000
    },
    {
      "epoch": 3.63,
      "grad_norm": 0.521811306476593,
      "learning_rate": 0.00011847457627118643,
      "loss": 7.2751,
      "step": 52500
    },
    {
      "epoch": 3.67,
      "grad_norm": 0.7036493420600891,
      "learning_rate": 0.00011674507090971982,
      "loss": 7.2733,
      "step": 53000
    },
    {
      "epoch": 3.7,
      "grad_norm": 0.5734107494354248,
      "learning_rate": 0.00011501556554825319,
      "loss": 7.2823,
      "step": 53500
    },
    {
      "epoch": 3.74,
      "grad_norm": 1.2899792194366455,
      "learning_rate": 0.00011328606018678657,
      "loss": 7.2695,
      "step": 54000
    },
    {
      "epoch": 3.77,
      "grad_norm": 0.9316887259483337,
      "learning_rate": 0.00011156001383604289,
      "loss": 7.2709,
      "step": 54500
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.5230897068977356,
      "learning_rate": 0.00010983050847457626,
      "loss": 7.2753,
      "step": 55000
    },
    {
      "epoch": 3.84,
      "grad_norm": 0.6711415648460388,
      "learning_rate": 0.00010810100311310964,
      "loss": 7.2708,
      "step": 55500
    },
    {
      "epoch": 3.87,
      "grad_norm": 0.9358042478561401,
      "learning_rate": 0.00010637149775164303,
      "loss": 7.2637,
      "step": 56000
    },
    {
      "epoch": 3.91,
      "grad_norm": 0.4522331655025482,
      "learning_rate": 0.0001046419923901764,
      "loss": 7.2679,
      "step": 56500
    },
    {
      "epoch": 3.94,
      "grad_norm": 0.9921635389328003,
      "learning_rate": 0.00010291248702870977,
      "loss": 7.2745,
      "step": 57000
    },
    {
      "epoch": 3.98,
      "grad_norm": 0.5565931797027588,
      "learning_rate": 0.0001011864406779661,
      "loss": 7.2655,
      "step": 57500
    },
    {
      "epoch": 4.0,
      "eval_bleu": 0.0,
      "eval_gen_len": 511.0,
      "eval_loss": 10.890857696533203,
      "eval_runtime": 8187.2193,
      "eval_samples_per_second": 1.044,
      "eval_steps_per_second": 0.065,
      "step": 57820
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.5502191185951233,
      "learning_rate": 9.945693531649947e-05,
      "loss": 7.278,
      "step": 58000
    },
    {
      "epoch": 4.05,
      "grad_norm": 0.7558137774467468,
      "learning_rate": 9.773088896575577e-05,
      "loss": 7.2532,
      "step": 58500
    },
    {
      "epoch": 4.08,
      "grad_norm": 0.4766830801963806,
      "learning_rate": 9.600138360428917e-05,
      "loss": 7.2625,
      "step": 59000
    },
    {
      "epoch": 4.12,
      "grad_norm": 0.5997222661972046,
      "learning_rate": 9.427187824282253e-05,
      "loss": 7.2564,
      "step": 59500
    },
    {
      "epoch": 4.15,
      "grad_norm": 0.65647953748703,
      "learning_rate": 9.254237288135593e-05,
      "loss": 7.2573,
      "step": 60000
    },
    {
      "epoch": 4.19,
      "grad_norm": 0.7757630348205566,
      "learning_rate": 9.081286751988931e-05,
      "loss": 7.2668,
      "step": 60500
    },
    {
      "epoch": 4.22,
      "grad_norm": 0.5260353088378906,
      "learning_rate": 8.908336215842268e-05,
      "loss": 7.2699,
      "step": 61000
    },
    {
      "epoch": 4.25,
      "grad_norm": 0.3896203637123108,
      "learning_rate": 8.7357315807679e-05,
      "loss": 7.2637,
      "step": 61500
    }
  ],
  "logging_steps": 500,
  "max_steps": 86730,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 6,
  "save_steps": 500,
  "total_flos": 1.554777373999104e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
