{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.9607042789442737,
  "eval_steps": 500,
  "global_step": 114500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02,
      "grad_norm": 1.9106252193450928,
      "learning_rate": 0.0002994811304438064,
      "loss": 8.0132,
      "step": 500
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.5251550674438477,
      "learning_rate": 0.00029896226088761284,
      "loss": 7.7063,
      "step": 1000
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.7006455659866333,
      "learning_rate": 0.00029844339133141927,
      "loss": 7.661,
      "step": 1500
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.3695513010025024,
      "learning_rate": 0.0002979245217752257,
      "loss": 7.6179,
      "step": 2000
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.0989121198654175,
      "learning_rate": 0.00029740565221903214,
      "loss": 7.5435,
      "step": 2500
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.2945663928985596,
      "learning_rate": 0.0002968867826628385,
      "loss": 7.493,
      "step": 3000
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.1160169839859009,
      "learning_rate": 0.00029636791310664495,
      "loss": 7.4565,
      "step": 3500
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.9569355249404907,
      "learning_rate": 0.0002958490435504514,
      "loss": 7.4079,
      "step": 4000
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.9714371562004089,
      "learning_rate": 0.0002953301739942578,
      "loss": 7.4081,
      "step": 4500
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.9875999689102173,
      "learning_rate": 0.00029481130443806424,
      "loss": 7.4175,
      "step": 5000
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.9777865409851074,
      "learning_rate": 0.0002942924348818707,
      "loss": 7.4062,
      "step": 5500
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.009952187538147,
      "learning_rate": 0.0002937735653256771,
      "loss": 7.4015,
      "step": 6000
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.7213172316551208,
      "learning_rate": 0.00029325469576948354,
      "loss": 7.3749,
      "step": 6500
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.8044652342796326,
      "learning_rate": 0.00029273582621328997,
      "loss": 7.3822,
      "step": 7000
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6163899898529053,
      "learning_rate": 0.0002922169566570964,
      "loss": 7.5117,
      "step": 7500
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6557358503341675,
      "learning_rate": 0.0002916980871009028,
      "loss": 7.5381,
      "step": 8000
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.7522820830345154,
      "learning_rate": 0.0002911792175447092,
      "loss": 7.4438,
      "step": 8500
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.8119372725486755,
      "learning_rate": 0.00029066034798851565,
      "loss": 7.3644,
      "step": 9000
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.7646867632865906,
      "learning_rate": 0.0002901414784323221,
      "loss": 7.3714,
      "step": 9500
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.7700051069259644,
      "learning_rate": 0.0002896226088761285,
      "loss": 7.3693,
      "step": 10000
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7914705276489258,
      "learning_rate": 0.00028910373931993494,
      "loss": 7.3441,
      "step": 10500
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.5692545175552368,
      "learning_rate": 0.0002885848697637414,
      "loss": 7.3556,
      "step": 11000
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.0443283319473267,
      "learning_rate": 0.0002880660002075478,
      "loss": 7.3489,
      "step": 11500
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.5541311502456665,
      "learning_rate": 0.00028754713065135424,
      "loss": 7.3726,
      "step": 12000
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.41806143522262573,
      "learning_rate": 0.0002870282610951607,
      "loss": 7.5219,
      "step": 12500
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.7863946557044983,
      "learning_rate": 0.00028650939153896705,
      "loss": 7.5203,
      "step": 13000
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5514603853225708,
      "learning_rate": 0.0002859905219827735,
      "loss": 7.4132,
      "step": 13500
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5185992121696472,
      "learning_rate": 0.00028547165242657997,
      "loss": 7.3797,
      "step": 14000
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.8605044484138489,
      "learning_rate": 0.00028495278287038635,
      "loss": 7.3533,
      "step": 14500
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6292963624000549,
      "learning_rate": 0.0002844339133141928,
      "loss": 7.3551,
      "step": 15000
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.6950894594192505,
      "learning_rate": 0.0002839150437579992,
      "loss": 7.3491,
      "step": 15500
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.7425427436828613,
      "learning_rate": 0.00028339617420180564,
      "loss": 7.3442,
      "step": 16000
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.8568000197410583,
      "learning_rate": 0.0002828773046456121,
      "loss": 7.368,
      "step": 16500
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.7571437358856201,
      "learning_rate": 0.0002823584350894185,
      "loss": 7.3466,
      "step": 17000
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.8919925093650818,
      "learning_rate": 0.00028183956553322494,
      "loss": 7.3526,
      "step": 17500
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.8631299138069153,
      "learning_rate": 0.0002813206959770313,
      "loss": 7.3328,
      "step": 18000
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.7783452272415161,
      "learning_rate": 0.00028080182642083775,
      "loss": 7.3419,
      "step": 18500
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.41514158248901367,
      "learning_rate": 0.00028028295686464424,
      "loss": 7.3472,
      "step": 19000
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.7073963284492493,
      "learning_rate": 0.0002797640873084506,
      "loss": 7.3321,
      "step": 19500
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.5550534725189209,
      "learning_rate": 0.00027924521775225705,
      "loss": 7.3417,
      "step": 20000
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.947964608669281,
      "learning_rate": 0.0002787263481960635,
      "loss": 7.343,
      "step": 20500
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.3077383041381836,
      "learning_rate": 0.0002782074786398699,
      "loss": 7.3329,
      "step": 21000
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.4680899977684021,
      "learning_rate": 0.00027768860908367635,
      "loss": 7.3389,
      "step": 21500
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.5247710347175598,
      "learning_rate": 0.0002771697395274828,
      "loss": 7.3466,
      "step": 22000
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.7990259528160095,
      "learning_rate": 0.0002766508699712892,
      "loss": 7.3192,
      "step": 22500
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.8314121961593628,
      "learning_rate": 0.0002761320004150956,
      "loss": 7.3403,
      "step": 23000
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.9423720836639404,
      "learning_rate": 0.000275613130858902,
      "loss": 7.3392,
      "step": 23500
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.4249916076660156,
      "learning_rate": 0.0002750942613027085,
      "loss": 7.3327,
      "step": 24000
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.5206239819526672,
      "learning_rate": 0.0002745753917465149,
      "loss": 7.3458,
      "step": 24500
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.597811222076416,
      "learning_rate": 0.0002740565221903213,
      "loss": 7.3244,
      "step": 25000
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.519999086856842,
      "learning_rate": 0.00027353765263412775,
      "loss": 7.3334,
      "step": 25500
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.44627055525779724,
      "learning_rate": 0.0002730187830779342,
      "loss": 7.3401,
      "step": 26000
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.4349792003631592,
      "learning_rate": 0.0002724999135217406,
      "loss": 7.3369,
      "step": 26500
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.0613300800323486,
      "learning_rate": 0.00027198104396554705,
      "loss": 7.3458,
      "step": 27000
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.6210318207740784,
      "learning_rate": 0.0002714621744093535,
      "loss": 7.3386,
      "step": 27500
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.41429609060287476,
      "learning_rate": 0.00027094330485315986,
      "loss": 7.3252,
      "step": 28000
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.44785159826278687,
      "learning_rate": 0.00027042443529696634,
      "loss": 7.335,
      "step": 28500
    },
    {
      "epoch": 1.0,
      "eval_bleu": 0.0,
      "eval_gen_len": 511.0,
      "eval_loss": 10.842129707336426,
      "eval_runtime": 9650.0986,
      "eval_samples_per_second": 0.886,
      "eval_steps_per_second": 0.111,
      "step": 28909
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.4267326295375824,
      "learning_rate": 0.0002699055657407728,
      "loss": 7.3168,
      "step": 29000
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.42268314957618713,
      "learning_rate": 0.00026938669618457915,
      "loss": 7.3288,
      "step": 29500
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.44057774543762207,
      "learning_rate": 0.0002688678266283856,
      "loss": 7.305,
      "step": 30000
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.7901044487953186,
      "learning_rate": 0.000268348957072192,
      "loss": 7.3018,
      "step": 30500
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.49083051085472107,
      "learning_rate": 0.00026783008751599845,
      "loss": 7.3325,
      "step": 31000
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.9547919631004333,
      "learning_rate": 0.0002673112179598049,
      "loss": 7.2916,
      "step": 31500
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.43799689412117004,
      "learning_rate": 0.0002667923484036113,
      "loss": 7.3053,
      "step": 32000
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.4564681947231293,
      "learning_rate": 0.00026627347884741775,
      "loss": 7.333,
      "step": 32500
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.8401866555213928,
      "learning_rate": 0.0002657546092912241,
      "loss": 7.3134,
      "step": 33000
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.6664919853210449,
      "learning_rate": 0.0002652357397350306,
      "loss": 7.3034,
      "step": 33500
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.9149719476699829,
      "learning_rate": 0.00026471687017883705,
      "loss": 7.3174,
      "step": 34000
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.5984742045402527,
      "learning_rate": 0.0002641980006226434,
      "loss": 7.3098,
      "step": 34500
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.6822497844696045,
      "learning_rate": 0.00026367913106644986,
      "loss": 7.3154,
      "step": 35000
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.9112513065338135,
      "learning_rate": 0.0002631602615102563,
      "loss": 7.3009,
      "step": 35500
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.729201078414917,
      "learning_rate": 0.0002626413919540627,
      "loss": 7.3115,
      "step": 36000
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.3882354199886322,
      "learning_rate": 0.00026212252239786915,
      "loss": 7.3224,
      "step": 36500
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.5118497610092163,
      "learning_rate": 0.0002616036528416756,
      "loss": 7.3322,
      "step": 37000
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.739855170249939,
      "learning_rate": 0.000261084783285482,
      "loss": 7.316,
      "step": 37500
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.0226681232452393,
      "learning_rate": 0.0002605659137292884,
      "loss": 7.3311,
      "step": 38000
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.606675922870636,
      "learning_rate": 0.0002600470441730949,
      "loss": 7.305,
      "step": 38500
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.4315951466560364,
      "learning_rate": 0.0002595281746169013,
      "loss": 7.2962,
      "step": 39000
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.5149005055427551,
      "learning_rate": 0.0002590093050607077,
      "loss": 7.3175,
      "step": 39500
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.41714322566986084,
      "learning_rate": 0.0002584904355045141,
      "loss": 7.302,
      "step": 40000
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.7527396082878113,
      "learning_rate": 0.00025797156594832056,
      "loss": 7.3112,
      "step": 40500
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.4622366726398468,
      "learning_rate": 0.000257452696392127,
      "loss": 7.3178,
      "step": 41000
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.6536469459533691,
      "learning_rate": 0.0002569338268359334,
      "loss": 7.3095,
      "step": 41500
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.4630104303359985,
      "learning_rate": 0.00025641495727973985,
      "loss": 7.3026,
      "step": 42000
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.42173752188682556,
      "learning_rate": 0.0002558960877235463,
      "loss": 7.3218,
      "step": 42500
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.7070847153663635,
      "learning_rate": 0.0002553772181673527,
      "loss": 7.3106,
      "step": 43000
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.5838462114334106,
      "learning_rate": 0.00025485834861115915,
      "loss": 7.2997,
      "step": 43500
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.47378984093666077,
      "learning_rate": 0.0002543394790549656,
      "loss": 7.2979,
      "step": 44000
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.3278196454048157,
      "learning_rate": 0.00025382060949877196,
      "loss": 7.32,
      "step": 44500
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.43107515573501587,
      "learning_rate": 0.0002533017399425784,
      "loss": 7.3078,
      "step": 45000
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.40634703636169434,
      "learning_rate": 0.0002527828703863848,
      "loss": 7.3219,
      "step": 45500
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.38711297512054443,
      "learning_rate": 0.00025226400083019126,
      "loss": 7.3121,
      "step": 46000
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.33697712421417236,
      "learning_rate": 0.0002517451312739977,
      "loss": 7.2952,
      "step": 46500
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.4709019958972931,
      "learning_rate": 0.0002512262617178041,
      "loss": 7.2919,
      "step": 47000
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.8913273215293884,
      "learning_rate": 0.00025070739216161056,
      "loss": 7.3156,
      "step": 47500
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.5656068325042725,
      "learning_rate": 0.000250188522605417,
      "loss": 7.3119,
      "step": 48000
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.6966277360916138,
      "learning_rate": 0.0002496696530492234,
      "loss": 7.3007,
      "step": 48500
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.3300257623195648,
      "learning_rate": 0.00024915078349302985,
      "loss": 7.3054,
      "step": 49000
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.4077496826648712,
      "learning_rate": 0.0002486319139368363,
      "loss": 7.3164,
      "step": 49500
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.5181363224983215,
      "learning_rate": 0.00024811304438064266,
      "loss": 7.3095,
      "step": 50000
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.9247940182685852,
      "learning_rate": 0.0002475941748244491,
      "loss": 7.2966,
      "step": 50500
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.6769075393676758,
      "learning_rate": 0.0002470753052682555,
      "loss": 7.3184,
      "step": 51000
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.3527926802635193,
      "learning_rate": 0.00024655643571206196,
      "loss": 7.306,
      "step": 51500
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.5137438178062439,
      "learning_rate": 0.0002460375661558684,
      "loss": 7.3044,
      "step": 52000
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.5840973854064941,
      "learning_rate": 0.0002455186965996748,
      "loss": 7.3127,
      "step": 52500
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.44899213314056396,
      "learning_rate": 0.00024499982704348126,
      "loss": 7.3095,
      "step": 53000
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.5254817605018616,
      "learning_rate": 0.0002444809574872877,
      "loss": 7.3036,
      "step": 53500
    },
    {
      "epoch": 1.87,
      "grad_norm": 1.2931712865829468,
      "learning_rate": 0.00024396208793109412,
      "loss": 7.2959,
      "step": 54000
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.8019412755966187,
      "learning_rate": 0.00024344321837490053,
      "loss": 7.3015,
      "step": 54500
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.43950435519218445,
      "learning_rate": 0.00024292434881870696,
      "loss": 7.309,
      "step": 55000
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.4233384132385254,
      "learning_rate": 0.00024240547926251336,
      "loss": 7.3159,
      "step": 55500
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.9384854435920715,
      "learning_rate": 0.00024188660970631982,
      "loss": 7.3199,
      "step": 56000
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.703903079032898,
      "learning_rate": 0.00024136774015012626,
      "loss": 7.2983,
      "step": 56500
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.7960612177848816,
      "learning_rate": 0.00024084887059393266,
      "loss": 7.304,
      "step": 57000
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.3758685886859894,
      "learning_rate": 0.0002403300010377391,
      "loss": 7.3094,
      "step": 57500
    },
    {
      "epoch": 2.0,
      "eval_bleu": 0.0,
      "eval_gen_len": 511.0,
      "eval_loss": 9.52863597869873,
      "eval_runtime": 9333.5537,
      "eval_samples_per_second": 0.916,
      "eval_steps_per_second": 0.115,
      "step": 57818
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.9319356679916382,
      "learning_rate": 0.0002398111314815455,
      "loss": 7.2696,
      "step": 58000
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.8099289536476135,
      "learning_rate": 0.00023929226192535196,
      "loss": 7.2889,
      "step": 58500
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.6975569128990173,
      "learning_rate": 0.0002387733923691584,
      "loss": 7.2948,
      "step": 59000
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.5098533034324646,
      "learning_rate": 0.0002382545228129648,
      "loss": 7.2905,
      "step": 59500
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.8788193464279175,
      "learning_rate": 0.00023773565325677123,
      "loss": 7.2885,
      "step": 60000
    },
    {
      "epoch": 2.09,
      "grad_norm": 1.261760950088501,
      "learning_rate": 0.00023721678370057763,
      "loss": 7.2904,
      "step": 60500
    },
    {
      "epoch": 2.11,
      "grad_norm": 1.1857478618621826,
      "learning_rate": 0.0002366979141443841,
      "loss": 7.2948,
      "step": 61000
    },
    {
      "epoch": 2.13,
      "grad_norm": 1.1026995182037354,
      "learning_rate": 0.00023617904458819052,
      "loss": 7.2851,
      "step": 61500
    },
    {
      "epoch": 2.14,
      "grad_norm": 0.5479902625083923,
      "learning_rate": 0.00023566017503199693,
      "loss": 7.3089,
      "step": 62000
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.41821175813674927,
      "learning_rate": 0.00023514130547580336,
      "loss": 7.2739,
      "step": 62500
    },
    {
      "epoch": 2.18,
      "grad_norm": 1.1070903539657593,
      "learning_rate": 0.00023462243591960977,
      "loss": 7.2868,
      "step": 63000
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.8069911599159241,
      "learning_rate": 0.00023410356636341623,
      "loss": 7.2837,
      "step": 63500
    },
    {
      "epoch": 2.21,
      "grad_norm": 0.7150157690048218,
      "learning_rate": 0.00023358469680722266,
      "loss": 7.2985,
      "step": 64000
    },
    {
      "epoch": 2.23,
      "grad_norm": 0.8092358112335205,
      "learning_rate": 0.00023306582725102906,
      "loss": 7.3066,
      "step": 64500
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.7031636238098145,
      "learning_rate": 0.0002325469576948355,
      "loss": 7.3058,
      "step": 65000
    },
    {
      "epoch": 2.27,
      "grad_norm": 1.475128412246704,
      "learning_rate": 0.0002320280881386419,
      "loss": 7.2719,
      "step": 65500
    },
    {
      "epoch": 2.28,
      "grad_norm": 0.40549755096435547,
      "learning_rate": 0.00023150921858244836,
      "loss": 7.2734,
      "step": 66000
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.33423662185668945,
      "learning_rate": 0.0002309903490262548,
      "loss": 7.2878,
      "step": 66500
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.2758391499519348,
      "learning_rate": 0.0002304714794700612,
      "loss": 7.2818,
      "step": 67000
    },
    {
      "epoch": 2.33,
      "grad_norm": 0.9789859056472778,
      "learning_rate": 0.00022995260991386763,
      "loss": 7.2923,
      "step": 67500
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.8060742616653442,
      "learning_rate": 0.00022943374035767404,
      "loss": 7.2821,
      "step": 68000
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.5950461626052856,
      "learning_rate": 0.0002289148708014805,
      "loss": 7.3148,
      "step": 68500
    },
    {
      "epoch": 2.39,
      "grad_norm": 0.84730464220047,
      "learning_rate": 0.00022839600124528693,
      "loss": 7.2783,
      "step": 69000
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.43369126319885254,
      "learning_rate": 0.00022787713168909333,
      "loss": 7.3046,
      "step": 69500
    },
    {
      "epoch": 2.42,
      "grad_norm": 0.8322641253471375,
      "learning_rate": 0.00022735826213289976,
      "loss": 7.2882,
      "step": 70000
    },
    {
      "epoch": 2.44,
      "grad_norm": 1.0166863203048706,
      "learning_rate": 0.00022683939257670617,
      "loss": 7.3173,
      "step": 70500
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.5530039072036743,
      "learning_rate": 0.00022632052302051263,
      "loss": 7.2792,
      "step": 71000
    },
    {
      "epoch": 2.47,
      "grad_norm": 0.8568323254585266,
      "learning_rate": 0.00022580165346431906,
      "loss": 7.29,
      "step": 71500
    },
    {
      "epoch": 2.49,
      "grad_norm": 0.5406705141067505,
      "learning_rate": 0.00022528278390812547,
      "loss": 7.2935,
      "step": 72000
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.7137210369110107,
      "learning_rate": 0.0002247639143519319,
      "loss": 7.2758,
      "step": 72500
    },
    {
      "epoch": 2.53,
      "grad_norm": 0.516574501991272,
      "learning_rate": 0.0002242450447957383,
      "loss": 7.279,
      "step": 73000
    },
    {
      "epoch": 2.54,
      "grad_norm": 0.6387965083122253,
      "learning_rate": 0.00022372617523954476,
      "loss": 7.3036,
      "step": 73500
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.30470001697540283,
      "learning_rate": 0.0002232073056833512,
      "loss": 7.2926,
      "step": 74000
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.5527244210243225,
      "learning_rate": 0.0002226884361271576,
      "loss": 7.2958,
      "step": 74500
    },
    {
      "epoch": 2.59,
      "grad_norm": 0.6642847657203674,
      "learning_rate": 0.00022216956657096403,
      "loss": 7.2947,
      "step": 75000
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.3530948758125305,
      "learning_rate": 0.00022165069701477044,
      "loss": 7.2977,
      "step": 75500
    },
    {
      "epoch": 2.63,
      "grad_norm": 1.0345615148544312,
      "learning_rate": 0.0002211318274585769,
      "loss": 7.2845,
      "step": 76000
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.4696452021598816,
      "learning_rate": 0.00022061295790238333,
      "loss": 7.2911,
      "step": 76500
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.47231510281562805,
      "learning_rate": 0.00022009408834618974,
      "loss": 7.2924,
      "step": 77000
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.3569483160972595,
      "learning_rate": 0.00021957521878999617,
      "loss": 7.2936,
      "step": 77500
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.8004411458969116,
      "learning_rate": 0.00021905634923380263,
      "loss": 7.2896,
      "step": 78000
    },
    {
      "epoch": 2.72,
      "grad_norm": 0.33754265308380127,
      "learning_rate": 0.00021853747967760903,
      "loss": 7.2862,
      "step": 78500
    },
    {
      "epoch": 2.73,
      "grad_norm": 0.3270581364631653,
      "learning_rate": 0.00021801861012141547,
      "loss": 7.2885,
      "step": 79000
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.7059010863304138,
      "learning_rate": 0.00021749974056522187,
      "loss": 7.3048,
      "step": 79500
    },
    {
      "epoch": 2.77,
      "grad_norm": 0.5090035796165466,
      "learning_rate": 0.0002169808710090283,
      "loss": 7.3147,
      "step": 80000
    },
    {
      "epoch": 2.78,
      "grad_norm": 0.7495837211608887,
      "learning_rate": 0.00021646200145283476,
      "loss": 7.3031,
      "step": 80500
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.6571905612945557,
      "learning_rate": 0.00021594313189664117,
      "loss": 7.2923,
      "step": 81000
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.3972395956516266,
      "learning_rate": 0.0002154242623404476,
      "loss": 7.2895,
      "step": 81500
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.49271005392074585,
      "learning_rate": 0.000214905392784254,
      "loss": 7.3054,
      "step": 82000
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.4039844572544098,
      "learning_rate": 0.00021438652322806044,
      "loss": 7.2824,
      "step": 82500
    },
    {
      "epoch": 2.87,
      "grad_norm": 0.8641160130500793,
      "learning_rate": 0.0002138676536718669,
      "loss": 7.2991,
      "step": 83000
    },
    {
      "epoch": 2.89,
      "grad_norm": 0.4174577593803406,
      "learning_rate": 0.0002133487841156733,
      "loss": 7.3015,
      "step": 83500
    },
    {
      "epoch": 2.91,
      "grad_norm": 0.4663136303424835,
      "learning_rate": 0.00021282991455947973,
      "loss": 7.2825,
      "step": 84000
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.512275218963623,
      "learning_rate": 0.00021231104500328614,
      "loss": 7.282,
      "step": 84500
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.6666954159736633,
      "learning_rate": 0.00021179217544709257,
      "loss": 7.2785,
      "step": 85000
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.3516216278076172,
      "learning_rate": 0.00021127330589089903,
      "loss": 7.2906,
      "step": 85500
    },
    {
      "epoch": 2.97,
      "grad_norm": 0.47365516424179077,
      "learning_rate": 0.00021075443633470544,
      "loss": 7.2861,
      "step": 86000
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.587658703327179,
      "learning_rate": 0.00021023556677851187,
      "loss": 7.2944,
      "step": 86500
    },
    {
      "epoch": 3.0,
      "eval_bleu": 0.0,
      "eval_gen_len": 511.0,
      "eval_loss": 9.60718822479248,
      "eval_runtime": 9449.1364,
      "eval_samples_per_second": 0.905,
      "eval_steps_per_second": 0.113,
      "step": 86727
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.3646923005580902,
      "learning_rate": 0.00020971669722231827,
      "loss": 7.2798,
      "step": 87000
    },
    {
      "epoch": 3.03,
      "grad_norm": 0.7572588324546814,
      "learning_rate": 0.0002091978276661247,
      "loss": 7.269,
      "step": 87500
    },
    {
      "epoch": 3.04,
      "grad_norm": 1.5926822423934937,
      "learning_rate": 0.00020867895810993117,
      "loss": 7.2845,
      "step": 88000
    },
    {
      "epoch": 3.06,
      "grad_norm": 0.4803914427757263,
      "learning_rate": 0.00020816008855373757,
      "loss": 7.2723,
      "step": 88500
    },
    {
      "epoch": 3.08,
      "grad_norm": 0.8872038722038269,
      "learning_rate": 0.000207641218997544,
      "loss": 7.285,
      "step": 89000
    },
    {
      "epoch": 3.1,
      "grad_norm": 0.8031995296478271,
      "learning_rate": 0.0002071223494413504,
      "loss": 7.2872,
      "step": 89500
    },
    {
      "epoch": 3.11,
      "grad_norm": 0.4891781806945801,
      "learning_rate": 0.00020660347988515684,
      "loss": 7.2772,
      "step": 90000
    },
    {
      "epoch": 3.13,
      "grad_norm": 0.6226624846458435,
      "learning_rate": 0.0002060846103289633,
      "loss": 7.2958,
      "step": 90500
    },
    {
      "epoch": 3.15,
      "grad_norm": 0.5093633532524109,
      "learning_rate": 0.0002055657407727697,
      "loss": 7.2545,
      "step": 91000
    },
    {
      "epoch": 3.17,
      "grad_norm": 0.6567374467849731,
      "learning_rate": 0.00020504687121657614,
      "loss": 7.3034,
      "step": 91500
    },
    {
      "epoch": 3.18,
      "grad_norm": 0.29156002402305603,
      "learning_rate": 0.00020452800166038257,
      "loss": 7.2777,
      "step": 92000
    },
    {
      "epoch": 3.2,
      "grad_norm": 1.0522457361221313,
      "learning_rate": 0.00020400913210418897,
      "loss": 7.2767,
      "step": 92500
    },
    {
      "epoch": 3.22,
      "grad_norm": 0.36653852462768555,
      "learning_rate": 0.00020349026254799543,
      "loss": 7.276,
      "step": 93000
    },
    {
      "epoch": 3.23,
      "grad_norm": 0.6330589652061462,
      "learning_rate": 0.00020297139299180184,
      "loss": 7.2912,
      "step": 93500
    },
    {
      "epoch": 3.25,
      "grad_norm": 0.9686583280563354,
      "learning_rate": 0.00020245252343560827,
      "loss": 7.2878,
      "step": 94000
    },
    {
      "epoch": 3.27,
      "grad_norm": 0.8373621702194214,
      "learning_rate": 0.0002019336538794147,
      "loss": 7.2714,
      "step": 94500
    },
    {
      "epoch": 3.29,
      "grad_norm": 0.9579115509986877,
      "learning_rate": 0.0002014147843232211,
      "loss": 7.2896,
      "step": 95000
    },
    {
      "epoch": 3.3,
      "grad_norm": 0.4163547158241272,
      "learning_rate": 0.00020089591476702757,
      "loss": 7.2806,
      "step": 95500
    },
    {
      "epoch": 3.32,
      "grad_norm": 0.38050195574760437,
      "learning_rate": 0.00020037704521083397,
      "loss": 7.2927,
      "step": 96000
    },
    {
      "epoch": 3.34,
      "grad_norm": 0.720497727394104,
      "learning_rate": 0.0001998581756546404,
      "loss": 7.287,
      "step": 96500
    },
    {
      "epoch": 3.36,
      "grad_norm": 0.49398136138916016,
      "learning_rate": 0.00019933930609844684,
      "loss": 7.2972,
      "step": 97000
    },
    {
      "epoch": 3.37,
      "grad_norm": 0.6455724239349365,
      "learning_rate": 0.00019882043654225324,
      "loss": 7.281,
      "step": 97500
    },
    {
      "epoch": 3.39,
      "grad_norm": 0.6803482174873352,
      "learning_rate": 0.0001983015669860597,
      "loss": 7.286,
      "step": 98000
    },
    {
      "epoch": 3.41,
      "grad_norm": 0.39570924639701843,
      "learning_rate": 0.0001977826974298661,
      "loss": 7.2803,
      "step": 98500
    },
    {
      "epoch": 3.42,
      "grad_norm": 0.556510865688324,
      "learning_rate": 0.00019726382787367254,
      "loss": 7.285,
      "step": 99000
    },
    {
      "epoch": 3.44,
      "grad_norm": 0.4138025641441345,
      "learning_rate": 0.00019674495831747897,
      "loss": 7.2955,
      "step": 99500
    },
    {
      "epoch": 3.46,
      "grad_norm": 1.1154133081436157,
      "learning_rate": 0.00019622608876128538,
      "loss": 7.2829,
      "step": 100000
    },
    {
      "epoch": 3.48,
      "grad_norm": 1.0153440237045288,
      "learning_rate": 0.00019570721920509184,
      "loss": 7.2792,
      "step": 100500
    },
    {
      "epoch": 3.49,
      "grad_norm": 0.4972051680088043,
      "learning_rate": 0.00019518834964889827,
      "loss": 7.3011,
      "step": 101000
    },
    {
      "epoch": 3.51,
      "grad_norm": 0.7825324535369873,
      "learning_rate": 0.00019466948009270468,
      "loss": 7.2935,
      "step": 101500
    },
    {
      "epoch": 3.53,
      "grad_norm": 0.4199385643005371,
      "learning_rate": 0.0001941506105365111,
      "loss": 7.2938,
      "step": 102000
    },
    {
      "epoch": 3.55,
      "grad_norm": 0.48886629939079285,
      "learning_rate": 0.0001936317409803175,
      "loss": 7.2621,
      "step": 102500
    },
    {
      "epoch": 3.56,
      "grad_norm": 0.4362781345844269,
      "learning_rate": 0.00019311287142412397,
      "loss": 7.2819,
      "step": 103000
    },
    {
      "epoch": 3.58,
      "grad_norm": 0.3631424605846405,
      "learning_rate": 0.0001925940018679304,
      "loss": 7.2878,
      "step": 103500
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.6374582648277283,
      "learning_rate": 0.0001920751323117368,
      "loss": 7.271,
      "step": 104000
    },
    {
      "epoch": 3.61,
      "grad_norm": 0.4208015501499176,
      "learning_rate": 0.00019155626275554324,
      "loss": 7.2696,
      "step": 104500
    },
    {
      "epoch": 3.63,
      "grad_norm": 0.9219037890434265,
      "learning_rate": 0.00019103739319934965,
      "loss": 7.2957,
      "step": 105000
    },
    {
      "epoch": 3.65,
      "grad_norm": 2.1098382472991943,
      "learning_rate": 0.0001905185236431561,
      "loss": 7.2739,
      "step": 105500
    },
    {
      "epoch": 3.67,
      "grad_norm": 0.6427266597747803,
      "learning_rate": 0.00018999965408696254,
      "loss": 7.2865,
      "step": 106000
    },
    {
      "epoch": 3.68,
      "grad_norm": 0.5802117586135864,
      "learning_rate": 0.00018948078453076894,
      "loss": 7.2944,
      "step": 106500
    },
    {
      "epoch": 3.7,
      "grad_norm": 0.510319173336029,
      "learning_rate": 0.00018896191497457538,
      "loss": 7.2882,
      "step": 107000
    },
    {
      "epoch": 3.72,
      "grad_norm": 0.615638256072998,
      "learning_rate": 0.00018844304541838178,
      "loss": 7.285,
      "step": 107500
    },
    {
      "epoch": 3.74,
      "grad_norm": 0.5490235686302185,
      "learning_rate": 0.00018792417586218824,
      "loss": 7.2765,
      "step": 108000
    },
    {
      "epoch": 3.75,
      "grad_norm": 0.42941874265670776,
      "learning_rate": 0.00018740530630599467,
      "loss": 7.2822,
      "step": 108500
    },
    {
      "epoch": 3.77,
      "grad_norm": 0.510755181312561,
      "learning_rate": 0.00018688643674980108,
      "loss": 7.2788,
      "step": 109000
    },
    {
      "epoch": 3.79,
      "grad_norm": 0.4554303288459778,
      "learning_rate": 0.0001863675671936075,
      "loss": 7.2723,
      "step": 109500
    },
    {
      "epoch": 3.81,
      "grad_norm": 1.5135849714279175,
      "learning_rate": 0.00018584869763741392,
      "loss": 7.2962,
      "step": 110000
    },
    {
      "epoch": 3.82,
      "grad_norm": 1.0973142385482788,
      "learning_rate": 0.00018532982808122038,
      "loss": 7.2826,
      "step": 110500
    },
    {
      "epoch": 3.84,
      "grad_norm": 0.4461710751056671,
      "learning_rate": 0.0001848109585250268,
      "loss": 7.2841,
      "step": 111000
    },
    {
      "epoch": 3.86,
      "grad_norm": 0.8005415201187134,
      "learning_rate": 0.0001842920889688332,
      "loss": 7.2802,
      "step": 111500
    },
    {
      "epoch": 3.87,
      "grad_norm": 0.41669508814811707,
      "learning_rate": 0.00018377321941263965,
      "loss": 7.2679,
      "step": 112000
    },
    {
      "epoch": 3.89,
      "grad_norm": 0.38158971071243286,
      "learning_rate": 0.00018325434985644605,
      "loss": 7.2704,
      "step": 112500
    },
    {
      "epoch": 3.91,
      "grad_norm": 0.42666923999786377,
      "learning_rate": 0.0001827354803002525,
      "loss": 7.2876,
      "step": 113000
    },
    {
      "epoch": 3.93,
      "grad_norm": 0.6128942370414734,
      "learning_rate": 0.00018221661074405894,
      "loss": 7.2952,
      "step": 113500
    },
    {
      "epoch": 3.94,
      "grad_norm": 0.6860007047653198,
      "learning_rate": 0.00018169774118786535,
      "loss": 7.2798,
      "step": 114000
    },
    {
      "epoch": 3.96,
      "grad_norm": 0.4247664511203766,
      "learning_rate": 0.00018117887163167178,
      "loss": 7.2769,
      "step": 114500
    }
  ],
  "logging_steps": 500,
  "max_steps": 289090,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "total_flos": 1.2966450856722432e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
