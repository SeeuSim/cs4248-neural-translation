{"cells":[{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-04-10T13:25:42.274098Z","iopub.status.busy":"2024-04-10T13:25:42.273067Z","iopub.status.idle":"2024-04-10T13:25:42.283896Z","shell.execute_reply":"2024-04-10T13:25:42.282899Z","shell.execute_reply.started":"2024-04-10T13:25:42.274058Z"},"trusted":true},"outputs":[],"source":["import string\n","import re\n","import os\n","import sys\n","from numpy import array, argmax, random, take\n","import pandas as pd\n","from keras.models import Sequential\n","from keras.layers import LSTM, Input, TimeDistributed, Dense, Activation, RepeatVector, Embedding\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from keras.callbacks import ModelCheckpoint\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import load_model, Model\n","from keras.losses import sparse_categorical_crossentropy\n","from keras import optimizers\n","from transformers import MarianTokenizer\n","\n","# import tensorflow_datasets as tfds\n","from datasets import Dataset, DatasetDict, load_dataset\n","\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","pd.set_option('display.max_colwidth', 200)"]},{"cell_type":"markdown","metadata":{},"source":["Fetch dataset (Kaggle)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-04-10T13:25:45.148167Z","iopub.status.busy":"2024-04-10T13:25:45.147772Z","iopub.status.idle":"2024-04-10T13:25:46.859079Z","shell.execute_reply":"2024-04-10T13:25:46.858165Z","shell.execute_reply.started":"2024-04-10T13:25:45.148136Z"},"trusted":true},"outputs":[],"source":["# train_ds = pd.read_csv(\"/kaggle/input/iwslt2017-en-zh/train.csv\")\n","# val_ds = pd.read_csv(\"/kaggle/input/iwslt2017-en-zh/validation.csv\")\n","# test_ds  = pd.read_csv(\"/kaggle/input/iwslt2017-en-zh/test.csv\")"]},{"cell_type":"markdown","metadata":{},"source":["Fetch dataset (Local)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['translation'],\n","    num_rows: 10000\n","})"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["dataset = load_dataset(\"iwslt2017\", \"iwslt2017-en-zh\")\n","train_ds, valid_ds, test_ds = (\n","    dataset[\"train\"],\n","    dataset[\"validation\"],\n","    dataset[\"test\"],\n",")\n","\n","# first 10k rows\n","train_ds = train_ds.select(range(10000))\n","train_ds"]},{"cell_type":"code","execution_count":12,"metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# (train_ds, test_ds, val_ds), metadata = tfds.load('huggingface:iwslt2017/iwslt2017-en-zh', split=['train[:10000]', 'test', 'validation'], with_info=True)\n","\n","# print(\"Dataset Structure:\")\n","# print(metadata.features)"]},{"cell_type":"code","execution_count":13,"metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# print(\"Train: %s \\nTest: %s \\nValidation: %s\" % (train_ds.cardinality().numpy(), test_ds.cardinality().numpy(), val_ds.cardinality().numpy()))"]},{"cell_type":"code","execution_count":14,"metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# Split en and zh\n","# texts_en = list()\n","# texts_zh = list()\n","# for elm in train_ds:\n","#     texts_en.append(elm['translation']['en'].numpy().decode(\"utf-8\"))\n","#     texts_zh.append(elm['translation']['zh'].numpy().decode(\"utf-8\"))\n","\n","# print(\"Train Lists created\")\n","# print(\"%s%s\" % (\"Size: \", len(texts_zh)))"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-04-10T13:25:50.662656Z","iopub.status.busy":"2024-04-10T13:25:50.662283Z","iopub.status.idle":"2024-04-10T13:25:50.682755Z","shell.execute_reply":"2024-04-10T13:25:50.681359Z","shell.execute_reply.started":"2024-04-10T13:25:50.662624Z"},"trusted":true},"outputs":[{"ename":"KeyError","evalue":"\"Column en not in the dataset. Current columns in the dataset: ['translation']\"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m texts_en \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_ds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43men\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m      2\u001b[0m texts_zh \u001b[38;5;241m=\u001b[39m train_ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzh\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(texts_zh)))\n","File \u001b[1;32mc:\\Users\\glenl\\anaconda3\\envs\\CS2109S\\lib\\site-packages\\datasets\\arrow_dataset.py:2810\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2808\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[0;32m   2809\u001b[0m     \u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[1;32m-> 2810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\glenl\\anaconda3\\envs\\CS2109S\\lib\\site-packages\\datasets\\arrow_dataset.py:2794\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[1;34m(self, key, **kwargs)\u001b[0m\n\u001b[0;32m   2792\u001b[0m format_kwargs \u001b[38;5;241m=\u001b[39m format_kwargs \u001b[38;5;28;01mif\u001b[39;00m format_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m   2793\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[1;32m-> 2794\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m \u001b[43mquery_table\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2795\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m format_table(\n\u001b[0;32m   2796\u001b[0m     pa_subtable, key, formatter\u001b[38;5;241m=\u001b[39mformatter, format_columns\u001b[38;5;241m=\u001b[39mformat_columns, output_all_columns\u001b[38;5;241m=\u001b[39moutput_all_columns\n\u001b[0;32m   2797\u001b[0m )\n\u001b[0;32m   2798\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n","File \u001b[1;32mc:\\Users\\glenl\\anaconda3\\envs\\CS2109S\\lib\\site-packages\\datasets\\formatting\\formatting.py:580\u001b[0m, in \u001b[0;36mquery_table\u001b[1;34m(table, key, indices)\u001b[0m\n\u001b[0;32m    578\u001b[0m     _raise_bad_key_type(key)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 580\u001b[0m     \u001b[43m_check_valid_column_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumn_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    581\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    582\u001b[0m     size \u001b[38;5;241m=\u001b[39m indices\u001b[38;5;241m.\u001b[39mnum_rows \u001b[38;5;28;01mif\u001b[39;00m indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m table\u001b[38;5;241m.\u001b[39mnum_rows\n","File \u001b[1;32mc:\\Users\\glenl\\anaconda3\\envs\\CS2109S\\lib\\site-packages\\datasets\\formatting\\formatting.py:520\u001b[0m, in \u001b[0;36m_check_valid_column_key\u001b[1;34m(key, columns)\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_valid_column_key\u001b[39m(key: \u001b[38;5;28mstr\u001b[39m, columns: List[\u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    519\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m columns:\n\u001b[1;32m--> 520\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in the dataset. Current columns in the dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumns\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[1;31mKeyError\u001b[0m: \"Column en not in the dataset. Current columns in the dataset: ['translation']\""]}],"source":["texts_en = train_ds['en'].tolist()\n","texts_zh = train_ds['zh'].tolist()\n","print(\"%s%s\" % (\"Size: \", len(texts_zh)))"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# max_len_en = 0\n","# longest_en = \"\"\n","# for text in texts_en:\n","#     if len(text) > max_len_en:\n","#         max_len_en = len(text)\n","#         longest_en = text\n","\n","# print(\"%s%s\" % (\"Max en sen len: \", max_len_en))\n","# print(longest_en)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# max_len_zh = 0\n","# longest_zh = \"\"\n","# for text in texts_zh:\n","#     if len(text) > max_len_zh:\n","#         max_len_zh = len(text)\n","#         longest_zh = text\n","\n","# print(\"%s%s\" % (\"Max zh sen len: \", max_len_zh))\n","# print(longest_zh)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# Split en and zh\n","# test_texts_en = list()\n","# test_texts_zh = list()\n","# for elm in test_ds:\n","#     test_texts_en.append(elm['translation']['en'].numpy().decode(\"utf-8\"))\n","#     test_texts_zh.append(elm['translation']['zh'].numpy().decode(\"utf-8\"))\n","\n","# print(\"Test Lists created\")\n","# print(\"%s%s\" % (\"Size: \", len(test_texts_en)))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-10T13:25:54.628408Z","iopub.status.busy":"2024-04-10T13:25:54.628053Z","iopub.status.idle":"2024-04-10T13:25:54.635004Z","shell.execute_reply":"2024-04-10T13:25:54.634018Z","shell.execute_reply.started":"2024-04-10T13:25:54.628381Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Lists created\n","Size: 8549\n"]}],"source":["test_texts_en = test_ds['en'].tolist()\n","test_texts_zh = test_ds['zh'].tolist()\n","print(\"Test Lists created\")\n","print(\"%s%s\" % (\"Size: \", len(test_texts_en)))"]},{"cell_type":"markdown","metadata":{},"source":["Tokenize"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-10T13:25:58.553625Z","iopub.status.busy":"2024-04-10T13:25:58.553273Z","iopub.status.idle":"2024-04-10T13:25:58.584960Z","shell.execute_reply":"2024-04-10T13:25:58.583864Z","shell.execute_reply.started":"2024-04-10T13:25:58.553600Z"},"trusted":true},"outputs":[],"source":["import sentencepiece as spm\n","from typing import List, Union\n","\n","class LangTokeniser(object):\n","    PAD_ID = 3  # Defined as sentencepiece custom token\n","\n","    def __init__(self, lang: str, model_file=None):\n","        self.model = spm.SentencePieceProcessor(model_file=model_file or f\"./{lang}.model\")\n","        self.special_ids = (\n","            self.model.unk_id(),\n","            LangTokeniser.PAD_ID,  # self.model.pad_id(), # this is -1 and may give errors.\n","            self.model.bos_id(),\n","            self.model.eos_id(),\n","        )\n","    \n","    def __len__(self):\n","        return len(self.model)\n","    \n","    def encode_no_padding(self, sent: Union[str, List[str]], max_len=None):\n","        ids = self.model.encode(sent)\n","        if max_len is not None and len(ids) > max_len:\n","            ids = ids[:max_len]\n","        return ids\n","\n","    def encode_batch(self, sents: List[str], max_len=None):\n","        return [self.encode(sent, max_len) for sent in sents]\n","\n","    def encode(self, sent: Union[str, List[str]], max_len=None):\n","        if isinstance(sent, list):\n","            return self.encode_batch(sent, max_len)\n","        ids = self.model.encode(sent)\n","        if max_len is not None:\n","            if len(ids) < max_len:\n","                ids.extend([LangTokeniser.PAD_ID] * (max_len - len(ids)))\n","            elif len(ids) > max_len:\n","                ids = ids[:max_len]\n","        return ids\n","\n","    def decode(self, ids: List[int]):\n","        return self.model.decode([id for id in ids if 0 <= id < len(self) and id != LangTokeniser.PAD_ID])\n","\n","    def decode_batch(self, ids: List[List[int]]):\n","        return [self.decode(id) for id in ids]\n","\n","    def get_special_ids(self):\n","        UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = self.special_ids\n","        return UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX\n","\n","\n","class BaseBPETokeniser(object):\n","    \"\"\"\n","    The class to tokenise input English sentences, and decode output Chinese Vocab IDs.\n","\n","    Examples:\n","    ```py\n","    from tokenisation.sentencepiece_custom import BaseBPETokeniser\n","\n","    tokeniser = BaseBPETokeniser()\n","    # or initialise with the model files in a separate path:\n","    tokeniser = BaseBPETokeniser(en_model_file=\"/path/to/en.model\", zh_model_file=\"/path/to/zh.model\")\n","\n","    row = dataset[0]['translation']\n","\n","    # Tokenise and truncate to max length of 512 for both.\n","    inputs = tokeniser(row['en'], text_target=row['zh'], max_len=512)\n","    # {\n","    #     'input_ids': [...],       # The English IDs\n","    #     'attention_mask': [...],\n","    #     'labels': [...]           # The Chinese IDs\n","    # }\n","\n","    # should generate the Chinese tokens output.\n","    translated = tokeniser.decode(ids)\n","\n","    ```\n","    \"\"\"\n","\n","    def __init__(self, en_model_file=None, zh_model_file=None):\n","        self.en_model = LangTokeniser(\"en\", model_file=en_model_file)\n","        self.zh_model = LangTokeniser(\"zh\", model_file=zh_model_file)\n","\n","    def __len__(self):\n","        \"\"\"\n","        Both the english and chinese tokenisers have the same length.\n","        \"\"\"\n","        return len(self.en_model)\n","\n","    def __call__(self, sent: str, text_target=None, max_len=128, max_zh_len=None):\n","        out = {\n","            \"input_ids\": self.en_model.encode(sent, max_len=max_len),\n","            \"attention_mask\": [1] * max_len,\n","        }\n","        if text_target:\n","            out[\"labels\"] = self.zh_model.encode(\n","                text_target, max_len=max_zh_len or max_len\n","            )\n","        return out\n","\n","    def encode_zh(self, sent: str, max_len=128):\n","        return self.zh_model.encode(sent, max_len=max_len)\n","\n","    def encode_en(self, sent: str, max_len=128):\n","        return self.en_model.encode(sent, max_len=max_len)\n","    \n","    def decode_zh(self, labels: list[int]):\n","        return self.zh_model.decode(labels)\n","\n","    def decode_zh_batch(self, labels: List[List[int]]):\n","        return self.zh_model.decode_batch(labels)\n","    \n","    def decode_en(self, labels: list[int]):\n","        return self.en_model.decode(labels)\n","\n","    def decode_en_batch(self, labels: list[int]):\n","        return self.en_model.decode_batch(labels)\n","    \n","    def get_special_ids(self, lang: str):\n","        if lang == \"en\":\n","            return self.en_model.get_special_ids()\n","        elif lang == \"zh\":\n","            return self.zh_model.get_special_ids()\n","\n","    def encode_en_no_padding(self, sent: str, max_len=None):\n","        return self.en_model.encode_no_padding(sent, max_len=max_len)\n","\n","    def encode_zh_no_padding(self, sent: str, max_len=None):\n","        return self.zh_model.encode_no_padding(sent, max_len=max_len)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-10T13:26:02.332992Z","iopub.status.busy":"2024-04-10T13:26:02.332575Z","iopub.status.idle":"2024-04-10T13:26:02.336868Z","shell.execute_reply":"2024-04-10T13:26:02.336132Z","shell.execute_reply.started":"2024-04-10T13:26:02.332959Z"},"trusted":true},"outputs":[],"source":["# sys.path.append(os.path.abspath('../../tokenisation/sentencepiece_custom'))\n","en_model_absolute_path = os.path.abspath('/kaggle/input/sentencepiece-models/en.model')\n","zh_model_absolute_path = os.path.abspath('/kaggle/input/sentencepiece-models/zh.model')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-10T13:26:04.449036Z","iopub.status.busy":"2024-04-10T13:26:04.448663Z","iopub.status.idle":"2024-04-10T13:26:04.501800Z","shell.execute_reply":"2024-04-10T13:26:04.500634Z","shell.execute_reply.started":"2024-04-10T13:26:04.449004Z"},"trusted":true},"outputs":[],"source":["tokenizer = BaseBPETokeniser(en_model_file=en_model_absolute_path, zh_model_file=zh_model_absolute_path)\n","\n","# If without padding\n","# encoded_en_no_padding = tokenizer.encode_en_no_padding(\"This is\", max_len=3)\n","# print(\"Encoded en:\", encoded_en_no_padding)\n","# encoded_zh_no_padding = tokenizer.encode_zh_no_padding(\"这是\", max_len=3)\n","# print(\"Encoded zh:\", encoded_zh_no_padding)\n","\n","# # Decoding (same) \n","# decoded_en = tokenizer.decode_src(encoded_en_no_padding)\n","# decoded_zh = tokenizer.decode(encoded_zh_no_padding)\n","\n","# decoded_en, decoded_zh"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# def tokenization(lines, is_char_level):\n","#     tokenizer = Tokenizer(char_level = is_char_level)\n","#     tokenizer.fit_on_texts(lines)\n","#     return tokenizer"]},{"cell_type":"markdown","metadata":{},"source":["Retrieve vocab from EN and CN files"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"execution":{"iopub.execute_input":"2024-04-10T13:26:18.680316Z","iopub.status.busy":"2024-04-10T13:26:18.679272Z","iopub.status.idle":"2024-04-10T13:26:18.734005Z","shell.execute_reply":"2024-04-10T13:26:18.733173Z","shell.execute_reply.started":"2024-04-10T13:26:18.680280Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# get the en vocab size\n","def read_vocab_file(vocab_file_path):\n","    vocab = {}\n","    with open(vocab_file_path, 'r', encoding='utf-8') as f:\n","        index = 0\n","        for line in f:\n","            token, ignore = line.strip().split()  # Assuming tokens and indices are separated by space\n","            vocab[token] = index \n","            index += 1\n","    return vocab\n","# retrieve en vocab\n","en_vocab_file = \"/kaggle/input/sentencepiece-vocabs/en.vocab\"\n","en_vocab = read_vocab_file(en_vocab_file)\n","# retrieve zh vocab\n","zh_vocab_file = \"/kaggle/input/sentencepiece-vocabs/zh.vocab\"\n","zh_vocab = read_vocab_file(zh_vocab_file)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# encode and pad sequences\n","# def encode_sequences(tokenizer, length, lines):\n","#     seq = tokenizer.texts_to_sequences(lines)\n","#     # pad sequences with 0 values\n","#     seq = pad_sequences(seq, maxlen=length, padding='post')\n","#     return seq"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-10T13:26:24.817433Z","iopub.status.busy":"2024-04-10T13:26:24.817050Z","iopub.status.idle":"2024-04-10T13:26:32.710603Z","shell.execute_reply":"2024-04-10T13:26:32.709182Z","shell.execute_reply.started":"2024-04-10T13:26:24.817402Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(211, 285)"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# encode english\n","max_len_en = len(max(tokenizer.encode_en_no_padding(texts_en), key=len))\n","# encode chinese\n","max_len_zh = len(max(tokenizer.encode_zh_no_padding(texts_zh), key=len))\n","max_len_en, max_len_zh"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# encode english\n","en_outputs = tokenizer.encode_en(texts_en, max_len=max_len_en)\n","# encode chinese\n","zh_outputs = tokenizer.encode_zh(texts_en, max_len=max_len_zh)\n","# prepare training data\n","# trainX = encode_sequences(en_tokenizer, en_length, texts_en)\n","# trainY = encode_sequences(zh_tokenizer, zh_length, texts_zh)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# len(trainX[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# prepare test data\n","# testX = encode_sequences(en_tokenizer, en_length, test_texts_en)\n","# testY = encode_sequences(zh_tokenizer, zh_length, test_texts_zh)\n"]},{"cell_type":"markdown","metadata":{},"source":["Build model"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# build NMT model\n","# def define_model(in_vocab,out_vocab, in_timesteps,out_timesteps,units):\n","#     model = Sequential()\n","#     model.add(Embedding(in_vocab, units, mask_zero=True))\n","#     model.add(LSTM(units))\n","#     model.add(RepeatVector(out_timesteps))\n","#     model.add(LSTM(units, return_sequences=True))\n","#     model.add(Dense(out_vocab, activation='softmax'))\n","#     return model"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# model compilation\n","# model = define_model(len(en_vocab), len(zh_vocab), max_len_en, max_len_zh, 512)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# rms = optimizers.RMSprop(learning_rate=0.001)\n","# model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')\n","# model.summary()"]},{"cell_type":"markdown","metadata":{},"source":["Build model (tutorial)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-10T13:27:13.131175Z","iopub.status.busy":"2024-04-10T13:27:13.130794Z","iopub.status.idle":"2024-04-10T13:27:13.265326Z","shell.execute_reply":"2024-04-10T13:27:13.264245Z","shell.execute_reply.started":"2024-04-10T13:27:13.131148Z"},"trusted":true},"outputs":[],"source":["input_sequence = Input(shape=(max_len_en,))\n","embedding = Embedding(input_dim=len(en_vocab), output_dim=128,)(input_sequence)\n","encoder = LSTM(64, return_sequences=False)(embedding)\n","r_vec = RepeatVector(max_len_zh)(encoder)\n","decoder = LSTM(64, return_sequences=True, dropout=0.2)(r_vec)\n","logits = TimeDistributed(Dense(len(zh_vocab)))(decoder)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-10T13:27:20.542165Z","iopub.status.busy":"2024-04-10T13:27:20.541734Z","iopub.status.idle":"2024-04-10T13:27:20.583559Z","shell.execute_reply":"2024-04-10T13:27:20.582574Z","shell.execute_reply.started":"2024-04-10T13:27:20.542123Z"},"trusted":true},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"functional_1\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">211</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">211</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,152</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ repeat_vector (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">285</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">285</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">285</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16384</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,064,960</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">285</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16384</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m211\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m211\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m2,097,152\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m49,408\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ repeat_vector (\u001b[38;5;33mRepeatVector\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m285\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m285\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m33,024\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m285\u001b[0m, \u001b[38;5;34m16384\u001b[0m)     │     \u001b[38;5;34m1,064,960\u001b[0m │\n","│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m285\u001b[0m, \u001b[38;5;34m16384\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,244,544</span> (12.38 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,244,544\u001b[0m (12.38 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,244,544</span> (12.38 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,244,544\u001b[0m (12.38 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"}],"source":["from keras.losses import sparse_categorical_crossentropy\n","from keras.optimizers import Adam\n","\n","model = Model(input_sequence, Activation('softmax')(logits))\n","model.compile(loss=sparse_categorical_crossentropy,\n","              optimizer=Adam(1e-3),\n","              metrics=['accuracy'])\n","model.summary()"]},{"cell_type":"markdown","metadata":{},"source":["Train the model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["en_outputs = array(en_outputs)\n","zh_outputs = array(zh_outputs)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["en_outputs.shape, zh_outputs.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["import time\n","filename = '/kaggle/working/' + str(time.time()) + \"_model.l5.07.keras\"\n","\n","checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n","\n","# train model\n","history = model.fit(en_outputs, zh_outputs.reshape(zh_outputs.shape[0], zh_outputs.shape[1], 1),\n","                    epochs=15, batch_size=32, validation_split = 0.2,callbacks=[checkpoint],\n","                    verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.legend(['train','validation'])\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["Load Model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import shutil\n","\n","# Specify the paths to the input and working directories\n","input_file_path = '../input/200k-trained-model/1712672287.5377033_model.l5.07.keras'\n","output_file_path = '/kaggle/working/200k_model.l5.07.keras'\n","\n","# Copy the file from the input directory to the working directory\n","shutil.copyfile(input_file_path, output_file_path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# from keras.models import load_model\n","\n","trainedModel = load_model(\"/kaggle/working/200k_model.l5.07.keras\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# en_outputs_list = en_outputs.tolist()\n","# zh_outputs_list = zh_outputs.tolist()\n","# check translation\n","example = en_outputs[40:41]\n","print(example)\n","print(tokenizer.decode_en_batch(example))\n","print(texts_en[40])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["list(zh_vocab.items())[:5]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def logits_to_sentence(logits, vocab):\n","\n","    index_to_words = {idx: word for word, idx in vocab.items()}\n","#     index_to_words[0] = '<empty>' \n","\n","    return ' '.join([index_to_words[prediction] for prediction in argmax(logits, 1)])\n","\n","index = 221000\n","print(\"The english sentence is: {}\".format(texts_en[index]))\n","print(\"The chinese sentence is: {}\".format(texts_zh[index]))\n","print('The predicted sentence is :')\n","print(logits_to_sentence(trainedModel.predict(array(en_outputs[index:index+1]))[0], zh_vocab))"]},{"cell_type":"markdown","metadata":{},"source":["Generate JSON of predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# import jieba\n","# import json\n","# import torch\n","# from bert_score import score\n","# from rouge_chinese import Rouge\n","# from sacrebleu.metrics import BLEU, CHRF, TER"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data = {}\n","# loop through first 10 test set\n","results = logits_to_sentence(trainedModel.predict(array(en_outputs[index:index+10]))[0], zh_vocab)\n","print(results)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4686007,"sourceId":7964922,"sourceType":"datasetVersion"},{"datasetId":4761650,"sourceId":8070132,"sourceType":"datasetVersion"},{"datasetId":4764020,"sourceId":8073332,"sourceType":"datasetVersion"},{"datasetId":4764259,"sourceId":8073656,"sourceType":"datasetVersion"},{"datasetId":4767679,"sourceId":8078323,"sourceType":"datasetVersion"}],"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.9"}},"nbformat":4,"nbformat_minor":4}
