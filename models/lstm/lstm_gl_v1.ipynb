{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-09T06:40:18.909777Z",
          "iopub.status.busy": "2024-04-09T06:40:18.909397Z",
          "iopub.status.idle": "2024-04-09T06:40:18.922135Z",
          "shell.execute_reply": "2024-04-09T06:40:18.921352Z",
          "shell.execute_reply.started": "2024-04-09T06:40:18.909748Z"
        },
        "id": "6o_iADy6rWth",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import re\n",
        "import os\n",
        "import sys\n",
        "from numpy import array, argmax, random, take\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Input, TimeDistributed, Dense, Activation, RepeatVector, Embedding\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model, Model\n",
        "from keras.losses import sparse_categorical_crossentropy\n",
        "from keras import optimizers\n",
        "from transformers import MarianTokenizer\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "from datasets import Dataset, DatasetDict, load_dataset\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "pd.set_option('display.max_colwidth', 200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnelPaX6rWth"
      },
      "source": [
        "Fetch dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-09T06:40:18.924294Z",
          "iopub.status.busy": "2024-04-09T06:40:18.923951Z",
          "iopub.status.idle": "2024-04-09T06:40:19.112184Z",
          "shell.execute_reply": "2024-04-09T06:40:19.111406Z",
          "shell.execute_reply.started": "2024-04-09T06:40:18.924264Z"
        },
        "id": "Ys5pNtdurWtj",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train_ds = pd.read_csv(\"/kaggle/input/iwslt2017-en-zh/train.csv\", nrows=10000)\n",
        "val_ds = pd.read_csv(\"/kaggle/input/iwslt2017-en-zh/validation.csv\", nrows=10000)\n",
        "test_ds  = pd.read_csv(\"/kaggle/input/iwslt2017-en-zh/test.csv\", nrows=10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-09T06:40:19.113649Z",
          "iopub.status.busy": "2024-04-09T06:40:19.11336Z",
          "iopub.status.idle": "2024-04-09T06:40:19.117858Z",
          "shell.execute_reply": "2024-04-09T06:40:19.116895Z",
          "shell.execute_reply.started": "2024-04-09T06:40:19.113624Z"
        },
        "id": "gfRuETVerWtj",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# (train_ds, test_ds, val_ds), metadata = tfds.load('huggingface:iwslt2017/iwslt2017-en-zh', split=['train[:10000]', 'test', 'validation'], with_info=True)\n",
        "\n",
        "# print(\"Dataset Structure:\")\n",
        "# print(metadata.features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-09T06:40:19.11921Z",
          "iopub.status.busy": "2024-04-09T06:40:19.118921Z",
          "iopub.status.idle": "2024-04-09T06:40:19.1287Z",
          "shell.execute_reply": "2024-04-09T06:40:19.127832Z",
          "shell.execute_reply.started": "2024-04-09T06:40:19.119166Z"
        },
        "id": "MBuLj8gKrWtk",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# print(\"Train: %s \\nTest: %s \\nValidation: %s\" % (train_ds.cardinality().numpy(), test_ds.cardinality().numpy(), val_ds.cardinality().numpy()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-09T06:40:19.131479Z",
          "iopub.status.busy": "2024-04-09T06:40:19.131115Z",
          "iopub.status.idle": "2024-04-09T06:40:19.138554Z",
          "shell.execute_reply": "2024-04-09T06:40:19.137736Z",
          "shell.execute_reply.started": "2024-04-09T06:40:19.131457Z"
        },
        "id": "RXFYZLL6rWtk",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Split en and zh\n",
        "# texts_en = list()\n",
        "# texts_zh = list()\n",
        "# for elm in train_ds:\n",
        "#     texts_en.append(elm['translation']['en'].numpy().decode(\"utf-8\"))\n",
        "#     texts_zh.append(elm['translation']['zh'].numpy().decode(\"utf-8\"))\n",
        "\n",
        "# print(\"Train Lists created\")\n",
        "# print(\"%s%s\" % (\"Size: \", len(texts_zh)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-09T06:40:19.140661Z",
          "iopub.status.busy": "2024-04-09T06:40:19.139948Z",
          "iopub.status.idle": "2024-04-09T06:40:19.156402Z",
          "shell.execute_reply": "2024-04-09T06:40:19.15553Z",
          "shell.execute_reply.started": "2024-04-09T06:40:19.140637Z"
        },
        "id": "LtoCHEowrWtl",
        "outputId": "407c184d-2215-42d8-b692-e659cfb0a32c",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size: 10000\n"
          ]
        }
      ],
      "source": [
        "texts_en = train_ds['en'].tolist()\n",
        "texts_zh = train_ds['zh'].tolist()\n",
        "print(\"%s%s\" % (\"Size: \", len(texts_zh)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-09T06:40:19.158373Z",
          "iopub.status.busy": "2024-04-09T06:40:19.157828Z",
          "iopub.status.idle": "2024-04-09T06:40:19.17041Z",
          "shell.execute_reply": "2024-04-09T06:40:19.169445Z",
          "shell.execute_reply.started": "2024-04-09T06:40:19.158343Z"
        },
        "id": "WLkdR23erWtm",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "d2fb551f-1e2c-446f-c1fa-e3a54edbf2b9",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max en sen len: 507\n",
            "And these couple clips take you inside of two of the most difficult conflicts that we're faced with today. [The last 48 hours of two Palestinian suicide bombers.] [Paradise Now] [Man: As long as there is injustice, someone must make a sacrifice!] [Woman: That's no sacrifice, that's revenge!] [If you kill, there's no difference between victim and occupier.] [Man: If we had airplanes, we wouldn't need martyrs, that's the difference.] [Woman: The difference is that the Israeli military is still stronger.]\n"
          ]
        }
      ],
      "source": [
        "max_len_en = 0\n",
        "longest_en = \"\"\n",
        "for text in texts_en:\n",
        "    if len(text) > max_len_en:\n",
        "        max_len_en = len(text)\n",
        "        longest_en = text\n",
        "\n",
        "print(\"%s%s\" % (\"Max en sen len: \", max_len_en))\n",
        "print(longest_en)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-09T06:40:19.172037Z",
          "iopub.status.busy": "2024-04-09T06:40:19.17167Z",
          "iopub.status.idle": "2024-04-09T06:40:19.182665Z",
          "shell.execute_reply": "2024-04-09T06:40:19.181909Z",
          "shell.execute_reply.started": "2024-04-09T06:40:19.172009Z"
        },
        "id": "Dus2QSA2rWtm",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "b51043d2-04dc-4a6f-9ca3-9d33eab8c8ca",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max zh sen len: 296\n",
            "其它叫法还有powder-box, derriere, pooky, poochy, poopy poopaloo, pooninana, padepachetchki, pow, peach  另外还可以别称作toadie, dee dee, nishi, dignity, coochie, snocher, cooter labi, gladis siegelman, va, wee-wee, whore-spot, nappy dugout mungo, ghoulie, powder-box, 在迈阿密叫mimi 在费城叫split knish, 在布朗克斯区叫schmende\n"
          ]
        }
      ],
      "source": [
        "max_len_zh = 0\n",
        "longest_zh = \"\"\n",
        "for text in texts_zh:\n",
        "    if len(text) > max_len_zh:\n",
        "        max_len_zh = len(text)\n",
        "        longest_zh = text\n",
        "\n",
        "print(\"%s%s\" % (\"Max zh sen len: \", max_len_zh))\n",
        "print(longest_zh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-09T06:40:19.184094Z",
          "iopub.status.busy": "2024-04-09T06:40:19.183782Z",
          "iopub.status.idle": "2024-04-09T06:40:19.19287Z",
          "shell.execute_reply": "2024-04-09T06:40:19.191802Z",
          "shell.execute_reply.started": "2024-04-09T06:40:19.184065Z"
        },
        "id": "r64CNGq-rWtn",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Split en and zh\n",
        "# test_texts_en = list()\n",
        "# test_texts_zh = list()\n",
        "# for elm in test_ds:\n",
        "#     test_texts_en.append(elm['translation']['en'].numpy().decode(\"utf-8\"))\n",
        "#     test_texts_zh.append(elm['translation']['zh'].numpy().decode(\"utf-8\"))\n",
        "\n",
        "# print(\"Test Lists created\")\n",
        "# print(\"%s%s\" % (\"Size: \", len(test_texts_en)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-09T06:40:19.19436Z",
          "iopub.status.busy": "2024-04-09T06:40:19.194081Z",
          "iopub.status.idle": "2024-04-09T06:40:19.204826Z",
          "shell.execute_reply": "2024-04-09T06:40:19.204059Z",
          "shell.execute_reply.started": "2024-04-09T06:40:19.194338Z"
        },
        "id": "6_PUxpWurWtn",
        "outputId": "b7772051-a51c-4f32-e714-d7e00ab040d3",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Lists created\n",
            "Size: 8549\n"
          ]
        }
      ],
      "source": [
        "test_texts_en = test_ds['en'].tolist()\n",
        "test_texts_zh = test_ds['zh'].tolist()\n",
        "print(\"Test Lists created\")\n",
        "print(\"%s%s\" % (\"Size: \", len(test_texts_en)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yygdbcygrWto"
      },
      "source": [
        "Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-09T06:40:19.205999Z",
          "iopub.status.busy": "2024-04-09T06:40:19.205745Z",
          "iopub.status.idle": "2024-04-09T06:40:19.214758Z",
          "shell.execute_reply": "2024-04-09T06:40:19.213959Z",
          "shell.execute_reply.started": "2024-04-09T06:40:19.205978Z"
        },
        "id": "lS_XqXeVrWto",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def tokenization(lines, is_char_level):\n",
        "    tokenizer = Tokenizer(char_level = is_char_level)\n",
        "    tokenizer.fit_on_texts(lines)\n",
        "    return tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-09T06:40:19.217636Z",
          "iopub.status.busy": "2024-04-09T06:40:19.215804Z",
          "iopub.status.idle": "2024-04-09T06:40:19.477943Z",
          "shell.execute_reply": "2024-04-09T06:40:19.477021Z",
          "shell.execute_reply.started": "2024-04-09T06:40:19.217606Z"
        },
        "id": "rQs2WG5ZrWto",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "43d370e4-83b5-47a7-92a7-ee79dbb30f74",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "en Vocabulary Size: 12214\n"
          ]
        }
      ],
      "source": [
        "# prepare en tokenizer\n",
        "en_tokenizer = tokenization(texts_en, False)\n",
        "en_vocab_size = len(en_tokenizer.word_index) + 1\n",
        "\n",
        "en_length = max_len_en\n",
        "print('en Vocabulary Size: %d' % en_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-09T06:40:19.479565Z",
          "iopub.status.busy": "2024-04-09T06:40:19.479171Z",
          "iopub.status.idle": "2024-04-09T06:40:19.712162Z",
          "shell.execute_reply": "2024-04-09T06:40:19.711192Z",
          "shell.execute_reply.started": "2024-04-09T06:40:19.47953Z"
        },
        "id": "Im1YVtwUrWto",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "6ca4028a-6de8-45b6-e175-a7ea1e1e44b4",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zh Vocabulary Size: 3044\n"
          ]
        }
      ],
      "source": [
        "# prepare zh tokenizer\n",
        "zh_tokenizer = tokenization(texts_zh, True)\n",
        "zh_vocab_size = len(zh_tokenizer.word_index) + 1\n",
        "\n",
        "zh_length = max_len_zh\n",
        "print('zh Vocabulary Size: %d' % zh_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-09T06:40:19.716448Z",
          "iopub.status.busy": "2024-04-09T06:40:19.716116Z",
          "iopub.status.idle": "2024-04-09T06:40:19.721645Z",
          "shell.execute_reply": "2024-04-09T06:40:19.720522Z",
          "shell.execute_reply.started": "2024-04-09T06:40:19.716421Z"
        },
        "id": "2SPSmPQQrWtp",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# encode and pad sequences\n",
        "def encode_sequences(tokenizer, length, lines):\n",
        "    seq = tokenizer.texts_to_sequences(lines)\n",
        "    # pad sequences with 0 values\n",
        "    seq = pad_sequences(seq, maxlen=length, padding='post')\n",
        "    return seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-09T06:40:19.723081Z",
          "iopub.status.busy": "2024-04-09T06:40:19.722822Z",
          "iopub.status.idle": "2024-04-09T06:40:20.171089Z",
          "shell.execute_reply": "2024-04-09T06:40:20.170076Z",
          "shell.execute_reply.started": "2024-04-09T06:40:19.723058Z"
        },
        "id": "sG5NE9bnrWtp",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# prepare training data\n",
        "trainX = encode_sequences(en_tokenizer, en_length, texts_en)\n",
        "trainY = encode_sequences(zh_tokenizer, zh_length, texts_zh)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-09T06:40:20.172479Z",
          "iopub.status.busy": "2024-04-09T06:40:20.172175Z",
          "iopub.status.idle": "2024-04-09T06:40:20.178771Z",
          "shell.execute_reply": "2024-04-09T06:40:20.177875Z",
          "shell.execute_reply.started": "2024-04-09T06:40:20.172456Z"
        },
        "id": "51I4fkizrWtp",
        "outputId": "b54b7da3-1ebe-451b-bc5e-1ae7c22f2c0a",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "507"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(trainX[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-09T06:40:20.180542Z",
          "iopub.status.busy": "2024-04-09T06:40:20.179923Z",
          "iopub.status.idle": "2024-04-09T06:40:20.537347Z",
          "shell.execute_reply": "2024-04-09T06:40:20.53636Z",
          "shell.execute_reply.started": "2024-04-09T06:40:20.180511Z"
        },
        "id": "WTA76fPzrWtp",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# prepare test data\n",
        "testX = encode_sequences(en_tokenizer, en_length, test_texts_en)\n",
        "testY = encode_sequences(zh_tokenizer, zh_length, test_texts_zh)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ig9vULqFrWtp"
      },
      "source": [
        "Build model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-09T06:40:20.53883Z",
          "iopub.status.busy": "2024-04-09T06:40:20.538541Z",
          "iopub.status.idle": "2024-04-09T06:40:20.54283Z",
          "shell.execute_reply": "2024-04-09T06:40:20.541982Z",
          "shell.execute_reply.started": "2024-04-09T06:40:20.538807Z"
        },
        "id": "Ma2O3nMirWtp",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# # build NMT model\n",
        "# def define_model(in_vocab,out_vocab, in_timesteps,out_timesteps,units):\n",
        "#     model = Sequential()\n",
        "#     model.add(Embedding(in_vocab, units, mask_zero=True))\n",
        "#     model.add(LSTM(units))\n",
        "#     model.add(RepeatVector(out_timesteps))\n",
        "#     model.add(LSTM(units, return_sequences=True))\n",
        "#     model.add(Dense(out_vocab, activation='softmax'))\n",
        "#     return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-09T06:40:20.544039Z",
          "iopub.status.busy": "2024-04-09T06:40:20.543795Z",
          "iopub.status.idle": "2024-04-09T06:40:20.553694Z",
          "shell.execute_reply": "2024-04-09T06:40:20.552867Z",
          "shell.execute_reply.started": "2024-04-09T06:40:20.544018Z"
        },
        "id": "r8RUYjuJrWtp",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# model compilation\n",
        "# model = define_model(en_vocab_size, zh_vocab_size, en_length, zh_length, 512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-09T06:40:20.55493Z",
          "iopub.status.busy": "2024-04-09T06:40:20.554675Z",
          "iopub.status.idle": "2024-04-09T06:40:20.564811Z",
          "shell.execute_reply": "2024-04-09T06:40:20.563874Z",
          "shell.execute_reply.started": "2024-04-09T06:40:20.554909Z"
        },
        "id": "D0EcPJAmrWtp",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# rms = optimizers.RMSprop(lr=0.001)\n",
        "# model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpPrxgZyrWtq"
      },
      "source": [
        "Build model (tutorial)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-09T06:40:20.566473Z",
          "iopub.status.busy": "2024-04-09T06:40:20.565982Z",
          "iopub.status.idle": "2024-04-09T06:40:20.61517Z",
          "shell.execute_reply": "2024-04-09T06:40:20.614525Z",
          "shell.execute_reply.started": "2024-04-09T06:40:20.566444Z"
        },
        "id": "hwETt_M_rWtq",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "input_sequence = Input(shape=(en_length,))\n",
        "embedding = Embedding(input_dim=en_vocab_size, output_dim=128,)(input_sequence)\n",
        "encoder = LSTM(64, return_sequences=False)(embedding)\n",
        "r_vec = RepeatVector(zh_length)(encoder)\n",
        "decoder = LSTM(64, return_sequences=True, dropout=0.2)(r_vec)\n",
        "logits = TimeDistributed(Dense(zh_vocab_size))(decoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-09T06:40:20.616306Z",
          "iopub.status.busy": "2024-04-09T06:40:20.616043Z",
          "iopub.status.idle": "2024-04-09T06:40:20.647016Z",
          "shell.execute_reply": "2024-04-09T06:40:20.646167Z",
          "shell.execute_reply.started": "2024-04-09T06:40:20.616285Z"
        },
        "id": "JXc1KXJgrWtq",
        "outputId": "f4b9d586-fda6-447f-fe26-6bf4c5d180b2",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">507</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">507</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,563,392</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ repeat_vector (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">296</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">296</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">296</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3044</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,860</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">296</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3044</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m507\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m507\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m1,563,392\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m49,408\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ repeat_vector (\u001b[38;5;33mRepeatVector\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m296\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m296\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m33,024\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m296\u001b[0m, \u001b[38;5;34m3044\u001b[0m)      │       \u001b[38;5;34m197,860\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m296\u001b[0m, \u001b[38;5;34m3044\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,843,684</span> (7.03 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,843,684\u001b[0m (7.03 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,843,684</span> (7.03 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,843,684\u001b[0m (7.03 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from keras.losses import sparse_categorical_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "model = Model(input_sequence, Activation('softmax')(logits))\n",
        "model.compile(loss=sparse_categorical_crossentropy,\n",
        "              optimizer=Adam(1e-3),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuUvsG5qrWtq"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wUNMXnWrWtq",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import time\n",
        "filename = '/kaggle/working/' + str(time.time()) + \"_model.l5.07.keras\"\n",
        "\n",
        "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "# train model\n",
        "history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1),\n",
        "                    epochs=30, batch_size=512, validation_split = 0.2,callbacks=[checkpoint],\n",
        "                    verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-09T06:40:27.640381Z",
          "iopub.status.idle": "2024-04-09T06:40:27.640815Z",
          "shell.execute_reply": "2024-04-09T06:40:27.640609Z",
          "shell.execute_reply.started": "2024-04-09T06:40:27.640591Z"
        },
        "id": "ewSRrPZCrWtq",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# plt.plot(history.history['loss'])\n",
        "# plt.plot(history.history['val_loss'])\n",
        "# plt.legend(['train','validation'])\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDpjplqsrWtr"
      },
      "source": [
        "Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-09T06:40:27.642249Z",
          "iopub.status.idle": "2024-04-09T06:40:27.642655Z",
          "shell.execute_reply": "2024-04-09T06:40:27.642488Z",
          "shell.execute_reply.started": "2024-04-09T06:40:27.642473Z"
        },
        "id": "Wf6LXmXxrWtr",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "# Specify the paths to the input and working directories\n",
        "input_file_path = '../input/model-kerastokenizer-v1/1712642755.4982576_model.l5.07.keras'\n",
        "output_file_path = '/kaggle/working/1712642755.4982576_model.l5.07.keras'\n",
        "\n",
        "# Copy the file from the input directory to the working directory\n",
        "shutil.copyfile(input_file_path, output_file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-09T06:40:49.259895Z",
          "iopub.status.busy": "2024-04-09T06:40:49.258998Z",
          "iopub.status.idle": "2024-04-09T06:40:49.557577Z",
          "shell.execute_reply": "2024-04-09T06:40:49.556734Z",
          "shell.execute_reply.started": "2024-04-09T06:40:49.25986Z"
        },
        "id": "j3yOWAHDrWtr",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "trainedModel = load_model(\"/kaggle/working/1712642755.4982576_model.l5.07.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-09T06:40:51.886852Z",
          "iopub.status.busy": "2024-04-09T06:40:51.886412Z",
          "iopub.status.idle": "2024-04-09T06:40:51.894102Z",
          "shell.execute_reply": "2024-04-09T06:40:51.893193Z",
          "shell.execute_reply.started": "2024-04-09T06:40:51.886819Z"
        },
        "id": "Ew3_UgonrWtr",
        "outputId": "ff62b2fd-72fa-4987-dfe4-c1fa798f0761",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['every time the tide comes in and out you find some more shells']"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check translation\n",
        "trainX[40:41]\n",
        "en_tokenizer.sequences_to_texts(trainX[40:41])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-09T06:56:15.108354Z",
          "iopub.status.busy": "2024-04-09T06:56:15.108013Z",
          "iopub.status.idle": "2024-04-09T06:56:15.289927Z",
          "shell.execute_reply": "2024-04-09T06:56:15.288893Z",
          "shell.execute_reply.started": "2024-04-09T06:56:15.10833Z"
        },
        "id": "z_8mAE0_rWts",
        "outputId": "34e338ba-bf3b-4819-88a6-8b9b1a5f8156",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The english sentence is: Can I be honest?\n",
            "The chinese sentence is: 我可以坦诚点吗？\n",
            "The predicted sentence is :\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step\n",
            "我 <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty> <empty>\n"
          ]
        }
      ],
      "source": [
        "def logits_to_sentence(logits, tokenizer):\n",
        "\n",
        "    index_to_words = {idx: word for word, idx in tokenizer.word_index.items()}\n",
        "    index_to_words[0] = '<empty>'\n",
        "\n",
        "    return ' '.join([index_to_words[prediction] for prediction in argmax(logits, 1)])\n",
        "\n",
        "index = 800\n",
        "print(\"The english sentence is: {}\".format(test_texts_en[index]))\n",
        "print(\"The chinese sentence is: {}\".format(test_texts_zh[index]))\n",
        "print('The predicted sentence is :')\n",
        "print(logits_to_sentence(trainedModel.predict(testX[index:index+1])[0], zh_tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-09T06:40:27.649657Z",
          "iopub.status.idle": "2024-04-09T06:40:27.650059Z",
          "shell.execute_reply": "2024-04-09T06:40:27.649872Z",
          "shell.execute_reply.started": "2024-04-09T06:40:27.649854Z"
        },
        "id": "CKNiKHoGrWts",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# a = trainedModel.predict(trainX[index:index+1])[0]\n",
        "# a"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "kev_lstm_v5",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 4686007,
          "sourceId": 7964922,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4761650,
          "sourceId": 8070132,
          "sourceType": "datasetVersion"
        }
      ],
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
